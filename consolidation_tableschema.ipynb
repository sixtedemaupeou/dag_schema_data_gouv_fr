{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from json import JSONDecodeError\n",
    "import chardet\n",
    "import csv\n",
    "from io import StringIO\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import os\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "import time\n",
    "import emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#API PARAMETERS\n",
    "\n",
    "#API_KEY = os.environ['DEMO_DATAGOUV_API_KEY']\n",
    "#Temporary :\n",
    "API_KEY = os.environ['DEMO_DATAGOUV_API_KEY_GEOFFREY']\n",
    "\n",
    "#API URL\n",
    "#api_url = 'https://demo.data.gouv.fr/api/1/'\n",
    "api_url = 'https://www.data.gouv.fr/api/1/'\n",
    "\n",
    "HEADERS = {\n",
    "    'X-API-KEY': API_KEY,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIL PARAMETERS\n",
    "smtp_host = os.environ['SCHEMA_BOT_MAIL_SMTP']\n",
    "smtp_user = os.environ['SCHEMA_BOT_MAIL_USER']\n",
    "smtp_password = os.environ['SCHEMA_BOT_MAIL_PASSWORD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/anthonyauffret/Projects/consolidation_schemas')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_path = Path(os.getenv('WORKING_DIR')) if os.getenv('WORKING_DIR') else Path().absolute()\n",
    "current_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = os.path.join(current_path, 'config_tableschema.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "schemas_list_url = 'https://raw.githubusercontent.com/etalab/schema.data.gouv.fr/master/aggregateur/data/schemas.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_url_base = api_url + 'datasets/?schema={schema_name}'\n",
    "tag_url_base = api_url + 'datasets/?tag={tag}'\n",
    "search_url_base = api_url + 'datasets?q={search_word}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "validata_base_url = \"https://validata-api-dev.app.etalab.studio/validate?schema={schema_url}&url={rurl}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Template for consolidation datasets title\n",
    "\n",
    "datasets_title_template = 'Fichiers consolidés des données respectant le schéma \"{schema_title}\"'\n",
    "\n",
    "#Template for consolidation datasets description (Markdown)\n",
    "\n",
    "datasets_description_template = '''\n",
    "Ceci est un jeu de données généré automatiquement par Etalab. Il regroupe les données qui respectent le schéma {schema_name}, par version du schéma.\n",
    "\n",
    "La fiche présentant le schéma et ses caractéristiques est disponible sur [https://schema.data.gouv.fr/{schema_name}/latest.html](https://schema.data.gouv.fr/{schema_name}/latest.html)\n",
    "\n",
    "### Qu'est-ce qu'un schéma ?\n",
    "\n",
    "Les schémas de données permettent de décrire des modèles de données : quels sont les différents champs, comment sont représentées les données, quelles sont les valeurs possibles, etc.\n",
    "\n",
    "Vous pouvez retrouver l'ensemble des schémas au référentiel sur le site schema.data.gouv.fr\n",
    "\n",
    "### Comment sont produites ces données ?\n",
    "\n",
    "Ces données sont produites à partir des ressources publiées sur le site [data.gouv.fr](http://data.gouv.fr) par différents producteurs. Etalab détecte automatiquement les ressources qui obéissent à un schéma et concatène l'ensemble des données en un seul fichier, par version de schéma.\n",
    "\n",
    "Ces fichiers consolidés permettent aux réutilisateurs de manipuler un seul fichier plutôt qu'une multitude de ressources et contribue ainsi à améliorer la qualité de l'open data.\n",
    "\n",
    "### Comment intégrer mes données dans ces fichiers consolidés ?\n",
    "\n",
    "Si vous êtes producteurs de données et que vous ne retrouvez pas vos données dans ces fichiers consolidés, c'est probablement parce que votre ressource sur [data.gouv.fr](http://data.gouv.fr) n'est pas conforme au schéma. Vous pouvez vérifier la conformité de votre ressource via l'outil [https://publier.etalab.studio/upload?schema={schema_name}](https://publier.etalab.studio/upload?schema={schema_name})\n",
    "\n",
    "En cas de problème persistant, vous pouvez contacter le support data.gouv [lien vers [https://support.data.gouv.fr/](https://support.data.gouv.fr/)].\n",
    "\n",
    "### Comment produire des données conformes ?\n",
    "\n",
    "Un certain nombre d'outils existent pour accompagner les producteurs de données. Vous pouvez notamment vous connecter sur le site [https://publier.etalab.studio/select?schema={schema_name}](https://publier.etalab.studio/select?schema={schema_name}) pour pouvoir saisir vos données selon trois modes :\n",
    "\n",
    "- upload de fichier existant\n",
    "- saisie via formulaire\n",
    "- saisie via tableur\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Template for mail/comment (added, updated and deleted schema)\n",
    "\n",
    "added_schema_comment_template = '''\n",
    "Bonjour,\n",
    "\n",
    "Vous recevez ce message car suite à un contrôle automatique de vos données par notre robot de validation, nous constatons que le fichier {resource_title} de ce jeu de données est conforme au schéma {schema_name} (version {most_recent_valid_version}).\n",
    "Nous avons donc automatiquement ajouté à ce fichier la métadonnée de schéma correspondante, ce qui atteste de la qualité des données que vous avez publiées.\n",
    "\n",
    "Une question ? Écrivez à validation@data.gouv.fr en incluant l'URL du jeu de données concerné.\n",
    "'''\n",
    "\n",
    "updated_schema_comment_template = '''\n",
    "Bonjour,\n",
    "\n",
    "Vous recevez ce message car suite à un contrôle automatique de vos données par notre robot de validation, nous constatons que le fichier {resource_title} de ce jeu de données (qui respecte le schéma {schema_name}) n'avait pas dans ses métadonnées la version de schéma la plus récente qu'il respecte.\n",
    "Nous avons donc automatiquement mis à jour les métadonnées du fichier en indiquant la version adéquate du schéma.\n",
    "\n",
    "Version précédemment indiquée : {initial_version_name}\n",
    "Version mise à jour : {most_recent_valid_version}\n",
    "\n",
    "Une question ? Écrivez à validation@data.gouv.fr en incluant l'URL du jeu de données concerné.\n",
    "'''\n",
    "\n",
    "deleted_schema_mail_template_org = '''\n",
    "Bonjour,<br />\n",
    "<br />\n",
    "Vous recevez ce message automatique car vous êtes admin de l'organisation {organisation_name} sur data.gouv.fr. Votre organisation a publié le jeu de données {dataset_title}, dont le fichier {resource_title} se veut conforme au schéma {schema_name}.<br />\n",
    "Cependant, suite à un contrôle automatique de vos données par notre robot de validation, il s'avère que ce fichier ne respecte aucune version de ce schéma.<br />\n",
    "Nous avons donc automatiquement supprimé la métadonnée de schéma associée à ce fichier.<br />\n",
    "<br />\n",
    "Vous pouvez consulter le [rapport de validation](https://validata.etalab.studio/table-schema?input=url&schema_url={schema_url}&url={resource_url}&repair=true) pour vous aider à corriger les erreurs (ce rapport est relatif à la version la plus récente du schéma, mais votre fichier a bien été testé vis-à-vis de toutes les versions possibles du schéma).<br />\n",
    "<br />\n",
    "Vous pourrez alors restaurer la métadonnée de schéma une fois un fichier valide publié.<br />\n",
    "<br />\n",
    "Une question ? Écrivez à validation@data.gouv.fr en incluant l'URL du jeu de données concerné.<br />\n",
    "<br />\n",
    "Cordialement,<br />\n",
    "<br />\n",
    "L'équipe de data.gouv.fr\n",
    "'''\n",
    "\n",
    "deleted_schema_mail_template_own = '''\n",
    "Bonjour,<br />\n",
    "<br />\n",
    "Vous recevez ce message automatique car vous avez publié sur data.gouv.fr le jeu de données {dataset_title}, dont le fichier {resource_title} se veut conforme au schéma {schema_name}.<br />\n",
    "Cependant, suite à un contrôle automatique de vos données par notre robot de validation, il s'avère que ce fichier ne respecte aucune version de ce schéma.<br />\n",
    "Nous avons donc automatiquement supprimé la métadonnée de schéma associée à ce fichier.<br />\n",
    "<br />\n",
    "Vous pouvez consulter le [rapport de validation](https://validata.etalab.studio/table-schema?input=url&schema_url={schema_url}&url={resource_url}&repair=true) pour vous aider à corriger les erreurs (ce rapport est relatif à la version la plus récente du schéma, mais votre fichier a bien été testé vis-à-vis de toutes les versions possibles du schéma).<br />\n",
    "<br />\n",
    "Vous pourrez alors restaurer la métadonnée de schéma une fois un fichier valide publié.<br />\n",
    "<br />\n",
    "Une question ? Écrivez à validation@data.gouv.fr en incluant l'URL du jeu de données concerné.<br />\n",
    "<br />\n",
    "Cordialement,<br />\n",
    "<br />\n",
    "L'équipe de data.gouv.fr\n",
    "'''\n",
    "\n",
    "deleted_schema_comment_template = '''\n",
    "Bonjour,\n",
    "\n",
    "Vous recevez ce message car suite à un contrôle automatique de vos données par notre robot de validation, nous constatons que le fichier {resource_title} de ce jeu de données se veut conforme au schéma {schema_name} alors qu'il ne respecte aucune version de ce schéma.\n",
    "Nous avons donc automatiquement supprimé la métadonnée de schéma associée à ce fichier.\n",
    "\n",
    "Vous pouvez consulter le [rapport de validation](https://validata.etalab.studio/table-schema?input=url&schema_url={schema_url}&url={resource_url}&repair=true) pour vous aider à corriger les erreurs (ce rapport est relatif à la version la plus récente du schéma, mais votre fichier a bien été testé vis-à-vis de toutes les versions possibles du schéma).\n",
    "\n",
    "Vous pourrez alors restaurer la métadonnée de schéma une fois un fichier valide publié.\n",
    "\n",
    "Une question ? Écrivez à validation@data.gouv.fr en incluant l'URL du jeu de données concerné.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_schema_dict(schema_name, schemas_catalogue_list) :\n",
    "    res = None\n",
    "    for schema in schemas_catalogue_list :\n",
    "        if schema['name'] == schema_name :\n",
    "            res = schema\n",
    "    \n",
    "    if res is None :\n",
    "        print(\"No schema named '{}' found.\".format(schema_name))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_schema_default_config(schema_name, config_path) :\n",
    "    \n",
    "    schema_dict = get_schema_dict(schema_name, schemas_catalogue_list)\n",
    "    schema_title = schema_dict['title']\n",
    "    \n",
    "    default_schema_config_dict = {\n",
    "        'consolidate': False,\n",
    "        'search_words':[schema_title] # setting schema title as a default search keyword for resources\n",
    "    }\n",
    "    \n",
    "    if os.path.exists(config_path) :\n",
    "        with open(config_path, 'r') as infile :\n",
    "            config_dict = yaml.safe_load(infile)\n",
    "    else :\n",
    "        config_dict = {}\n",
    "        \n",
    "    config_dict[schema_name] = default_schema_config_dict\n",
    "    \n",
    "    with open(config_path, 'w') as outfile:\n",
    "        yaml.dump(config_dict, outfile, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_api(url):\n",
    "    r = requests.get(url)\n",
    "    data = r.json()\n",
    "    nb_pages = int(data['total']/data['page_size'])+1\n",
    "    arr = []\n",
    "    for i in range(1,nb_pages+1):\n",
    "        r = requests.get(url+\"&page=\"+str(i))\n",
    "        data = r.json()\n",
    "        for dataset in data['data']:\n",
    "            for res in dataset['resources']:\n",
    "                if 'format=csv' in res['url']:\n",
    "                    filename = res['url'].split('/')[-3] + '.csv'\n",
    "                else:\n",
    "                    filename = res['url'].split('/')[-1]\n",
    "                ext = filename.split('.')[-1]\n",
    "                obj = {}\n",
    "                obj['dataset_id'] = dataset['id']\n",
    "                obj['dataset_title'] = dataset['title']\n",
    "                obj['dataset_slug'] = dataset['slug']\n",
    "                obj['dataset_page'] = dataset['page']\n",
    "                obj['resource_id'] = res['id']\n",
    "                obj['resource_title'] = res['title']\n",
    "                obj['resource_url'] = res['url']\n",
    "                obj['resource_last_modified'] = res['last_modified']\n",
    "                if ext != 'csv':\n",
    "                    obj['error_type'] = \"wrong-file-format\"\n",
    "                else:\n",
    "                    if not dataset['organization'] and not dataset['owner']:\n",
    "                        obj['error_type'] = \"orphan-dataset\"\n",
    "                    else:\n",
    "                        obj['organization_or_owner'] = dataset['organization']['slug'] if dataset['organization'] else dataset['owner']['slug']\n",
    "                        obj['error_type'] = None\n",
    "                arr.append(obj)\n",
    "    df = pd.DataFrame(arr)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_validata_report(rurl, schema_url, validata_base_url=validata_base_url) :\n",
    "    r = requests.get(validata_base_url.format(schema_url=schema_url, rurl=rurl))\n",
    "    time.sleep(0.5)\n",
    "    return r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_validata_valid(rurl, schema_url, validata_base_url=validata_base_url) :\n",
    "    try :\n",
    "        report = make_validata_report(rurl, schema_url, validata_base_url=validata_base_url)\n",
    "        try :\n",
    "            res = report['report']['valid']\n",
    "        except KeyError :\n",
    "            print('{} ---- 🔴 No info in validata report for resource: {} (ERROR MESSAGE: {})'.format(datetime.today(), rurl, report['message']))\n",
    "            res = False\n",
    "    except JSONDecodeError :\n",
    "        print('{} ---- 🔴 Could not make JSON from validata report for resource: {}'.format(datetime.today(), rurl))\n",
    "        res = False\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_validata_valid_row(row, schema_url) :\n",
    "    if row['error_type'] is None : #if no error\n",
    "        rurl = row['resource_url']\n",
    "        return is_validata_valid(rurl, schema_url)\n",
    "    else :\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_schema_consolidation_dataset(schema_name, schemas_catalogue_list, api_url) :\n",
    "    global HEADERS, datasets_description_template, datasets_title_template\n",
    "    \n",
    "    schema_title = get_schema_dict(schema_name, schemas_catalogue_list)['title']\n",
    "    \n",
    "    response = requests.post(api_url + 'datasets/', json={\n",
    "    'title': datasets_title_template.format(schema_title=schema_title),\n",
    "    'description': datasets_description_template.format(schema_name=schema_name),\n",
    "    'organization':'534fff75a3a7292c64a77de4',\n",
    "    'license':'lov2'\n",
    "    }, headers=HEADERS)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_config_file(schema_name, key, value, config_path) :\n",
    "    with open(config_path, 'r') as f :\n",
    "        config_dict = yaml.safe_load(f)\n",
    "    \n",
    "    config_dict[schema_name][key] = value\n",
    "    \n",
    "    with open(config_path, 'w') as outfile:\n",
    "        yaml.dump(config_dict, outfile, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_config_version_resource_id(schema_name, version_name, r_id, config_path) :\n",
    "    with open(config_path, 'r') as f :\n",
    "        config_dict = yaml.safe_load(f)\n",
    "    \n",
    "    if 'latest_resource_ids' not in config_dict[schema_name] :\n",
    "        config_dict[schema_name]['latest_resource_ids'] = {version_name: r_id}\n",
    "    else :\n",
    "        config_dict[schema_name]['latest_resource_ids'][version_name] = r_id\n",
    "        \n",
    "    with open(config_path, 'w') as outfile:\n",
    "        yaml.dump(config_dict, outfile, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_most_recent_valid_version(df_ref) :\n",
    "    \n",
    "    version_cols_list = [col for col in df_ref.columns if col.startswith('is_valid_v_')]\n",
    "    \n",
    "    df_ref['most_recent_valid_version'] = ''\n",
    "    \n",
    "    for col in sorted(version_cols_list, reverse=True) :\n",
    "        df_ref.loc[(df_ref['most_recent_valid_version'] == ''), 'most_recent_valid_version'] = df_ref.loc[(df_ref['most_recent_valid_version'] == ''), col].apply(lambda x : x*col.replace('is_valid_v_',''))\n",
    "    \n",
    "    df_ref.loc[(df_ref['most_recent_valid_version'] == ''), 'most_recent_valid_version'] = np.nan\n",
    "    \n",
    "    return df_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resource_schema_version(row, api_url) :\n",
    "    \n",
    "    dataset_id = row['dataset_id']\n",
    "    resource_id = row['resource_id']\n",
    "    \n",
    "    url = api_url + 'datasets/{}/resources/{}/'.format(dataset_id, resource_id)\n",
    "    r = requests.get(url)\n",
    "    if r.status_code == 200 :\n",
    "        r_json = r.json()\n",
    "        if 'schema' in r_json.keys() :\n",
    "            if 'version' in r_json['schema'].keys() :\n",
    "                return r_json['schema']['version']\n",
    "            else :\n",
    "                return np.nan\n",
    "        else :\n",
    "            return np.nan\n",
    "    else :\n",
    "        return np.nan\n",
    "\n",
    "def is_schema_version_to_update(row) :\n",
    "    initial_version_name = row['initial_version_name']\n",
    "    most_recent_valid_version = row['most_recent_valid_version']\n",
    "    resource_found_by = row['resource_found_by']\n",
    "    \n",
    "    return (resource_found_by == '1 - schema request') and (most_recent_valid_version == most_recent_valid_version) and (initial_version_name != most_recent_valid_version)\n",
    "    \n",
    "def is_schema_to_add(row) :\n",
    "    resource_found_by = row['resource_found_by']\n",
    "    is_valid_one_version = row['is_valid_one_version']\n",
    "    \n",
    "    return (resource_found_by != '1 - schema request') and is_valid_one_version\n",
    "    \n",
    "def is_schema_to_drop(row) :\n",
    "    resource_found_by = row['resource_found_by']\n",
    "    is_valid_one_version = row['is_valid_one_version']\n",
    "    \n",
    "    return (resource_found_by == '1 - schema request') and (is_valid_one_version == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_resource_schema(api_url, dataset_id, resource_id, schema_name, version_name) :\n",
    "    \n",
    "    global HEADERS\n",
    "    \n",
    "    schema = {\n",
    "        \"name\": schema_name,\n",
    "        \"version\": version_name\n",
    "    }\n",
    "    \n",
    "    extras = {\n",
    "        'consolidation_schema:add_schema': schema_name\n",
    "    }\n",
    "    \n",
    "    obj = {'schema': schema, 'extras': extras}\n",
    "                \n",
    "    url = api_url + 'datasets/{}/resources/{}/'.format(dataset_id, resource_id)\n",
    "    response = requests.put(url, json=obj, headers=HEADERS)\n",
    "    \n",
    "    if response.status_code != 200 :\n",
    "        print('🔴 Schema could not be added on resource. Dataset ID: {} - Resource ID: {}'.format(dataset_id, resource_id))\n",
    "        \n",
    "    return response.status_code == 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_resource_schema(api_url, dataset_id, resource_id, schema_name, version_name) :\n",
    "    \n",
    "    global HEADERS\n",
    "    \n",
    "    schema = {\n",
    "        \"name\": schema_name,\n",
    "        \"version\": version_name\n",
    "    }\n",
    "    \n",
    "    extras = {\n",
    "        'consolidation_schema:update_schema': schema_name\n",
    "    }\n",
    "    \n",
    "    obj = {'schema': schema, 'extras': extras}\n",
    "                \n",
    "    url = api_url + 'datasets/{}/resources/{}/'.format(dataset_id, resource_id)\n",
    "    response = requests.put(url, json=obj, headers=HEADERS)\n",
    "    \n",
    "    if response.status_code != 200 :\n",
    "        print('🔴 Resource schema could not be updated. Dataset ID: {} - Resource ID: {}'.format(dataset_id, resource_id))\n",
    "        \n",
    "    return response.status_code == 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_resource_schema(api_url, dataset_id, resource_id, initial_schema_name) :\n",
    "    \n",
    "    global HEADERS\n",
    "    \n",
    "    schema = {}\n",
    "    \n",
    "    extras = {\n",
    "        'consolidation_schema:remove_schema': schema_name\n",
    "    }\n",
    "    \n",
    "    obj = {'schema': schema, 'extras': extras}\n",
    "                \n",
    "    url = api_url + 'datasets/{}/resources/{}/'.format(dataset_id, resource_id)\n",
    "    response = requests.put(url, json=obj, headers=HEADERS)\n",
    "    \n",
    "    if response.status_code != 200 :\n",
    "        print('🔴 Resource schema could not be deleted. Dataset ID: {} - Resource ID: {}'.format(dataset_id, resource_id))\n",
    "    \n",
    "    return response#.status_code == 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_owner_or_admin_mails(dataset_id, api_url) :\n",
    "    r = requests.get(api_url + 'datasets/{}/'.format(dataset_id))\n",
    "    r_dict = r.json()\n",
    "    \n",
    "    if r_dict['organization'] is not None :\n",
    "        org_id = r_dict['organization']['id']\n",
    "    else :\n",
    "        org_id = None\n",
    "    \n",
    "    if r_dict['owner'] is not None :\n",
    "        owner_id = r_dict['owner']['id']\n",
    "    else :\n",
    "        owner_id = None\n",
    "    \n",
    "    mails_type = None\n",
    "    mails_list = []\n",
    "    \n",
    "    if org_id is not None :\n",
    "        mails_type = 'organisation_admins'\n",
    "        r_org = requests.get(api_url + 'organizations/{}/'.format(org_id))\n",
    "        members_list = r_org.json()['members']\n",
    "        for member in members_list :\n",
    "            if member['role'] == 'admin' :\n",
    "                user_id = member['user']['id']\n",
    "                r_user = requests.get(api_url + 'users/{}/'.format(user_id), headers=HEADER)\n",
    "                user_mail = r_user.json()['email']\n",
    "                mails_list += [user_mail]\n",
    "                \n",
    "    else :\n",
    "        if owner_id is not None :\n",
    "            mails_type = 'owner'\n",
    "            r_user = requests.get(api_url + 'users/{}/'.format(owner_id), headers=HEADER)\n",
    "            user_mail = r_user.json()['email']\n",
    "            mails_list += [user_mail]\n",
    "    \n",
    "    return (mails_type, mails_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sending mail\n",
    "def send_email(subject, message, mail_from, mail_to, smtp_host, smtp_user, smtp_password):\n",
    "    message = emails.html(html='<p>%s</p>' % message,\n",
    "                        subject=subject,\n",
    "                        mail_from=mail_from)\n",
    "    smtp = {\n",
    "        'host': smtp_host,\n",
    "        'port': 587,\n",
    "        'tls': True,\n",
    "        'user': smtp_user,\n",
    "        'password': smtp_password,\n",
    "    }\n",
    "\n",
    "    _ = message.send(to=mail_to, smtp=smtp)\n",
    "    \n",
    "    return _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_comment_on_dataset(dataset_id, title, comment, api_url) :\n",
    "    \n",
    "    global HEADER\n",
    "    \n",
    "    post_object = {\n",
    "        'title':title,\n",
    "        'comment' : comment,\n",
    "        'subject': {'class': 'Dataset', 'id': dataset_id}\n",
    "    }\n",
    "    \n",
    "    _ = requests.post(api_url + 'discussions/', json=post_object, headers=HEADER)\n",
    "    \n",
    "    return _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20211012\n"
     ]
    }
   ],
   "source": [
    "consolidation_date_str = datetime.now().strftime('%Y%m%d')\n",
    "print(consolidation_date_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = current_path / 'data' / 'tableschema' / consolidation_date_str\n",
    "data_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "consolidated_data_path = current_path / 'consolidated_data' / 'tableschema' / consolidation_date_str\n",
    "consolidated_data_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_tables_path = current_path / 'ref_tables' / 'tableschema' / consolidation_date_str\n",
    "ref_tables_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_tables_path = current_path / 'report_tables' / 'tableschema' / consolidation_date_str\n",
    "report_tables_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading schemas documentation and config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schemas documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep **only table schemas**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema catalogue URL: https://opendataschema.frama.io/catalog/schema-catalog.json\n",
      "Version: 1\n",
      "Total number of schemas: 24\n",
      "- etalab/schema-irve (7 versions)\n",
      "- etalab/schema-decp-dpa (1 versions)\n",
      "- scdl/catalogue (2 versions)\n",
      "- scdl/deliberations (6 versions)\n",
      "- scdl/equipements (2 versions)\n",
      "- scdl/subventions (3 versions)\n",
      "- etalab/schema-lieux-covoiturage (6 versions)\n",
      "- etalab/schema-stationnement (5 versions)\n",
      "- scdl/budget (1 versions)\n",
      "- arsante/schema-dae (3 versions)\n",
      "- NaturalSolutions/schema-arbre (4 versions)\n",
      "- etalab/schema-stationnement-cyclable (4 versions)\n",
      "- etalab/schema-inclusion-numerique (1 versions)\n",
      "- etalab/schema-hautes-remunerations (1 versions)\n",
      "- scdl/menus-collectifs (9 versions)\n",
      "- scdl/plats-menus-collectifs (4 versions)\n",
      "- MTES-MCT/acceslibre-schema (1 versions)\n",
      "- etalab/schema-sdirve (1 versions)\n",
      "- Archivistes75/registre_entrees (1 versions)\n",
      "- CEREMA/schema-arrete-circulation-marchandises (8 versions)\n",
      "- openmaraude/schema-stationstaxi (2 versions)\n",
      "- etalab/schema-vehicules-faibles-emissions-renouvellement-parc (2 versions)\n",
      "- datakode/schema-pei (1 versions)\n",
      "- etalab/schema-passage-a-niveau (1 versions)\n"
     ]
    }
   ],
   "source": [
    "# Getting schemas list :\n",
    "\n",
    "#Keeping track of schema info\n",
    "schemas_report_dict = {}\n",
    "\n",
    "schemas_catalogue_dict = requests.get(schemas_list_url).json()\n",
    "print('Schema catalogue URL: {}'.format(schemas_catalogue_dict['$schema']))\n",
    "print('Version: {}'.format(schemas_catalogue_dict['version']))\n",
    "\n",
    "schemas_catalogue_list = [schema for schema in schemas_catalogue_dict['schemas'] if schema['schema_type'] == 'tableschema']\n",
    "nb_schemas = len(schemas_catalogue_list)\n",
    "print('Total number of schemas: {}'.format(nb_schemas))\n",
    "\n",
    "for schema in schemas_catalogue_list :\n",
    "    print('- {} ({} versions)'.format(schema['name'], len(schema['versions'])))\n",
    "    schemas_report_dict[schema['name']] = {'nb_versions':len(schema['versions'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating config file with missing schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-12 11:33:12.083954 - ➕ Schema etalab/schema-irve added to config file.\n",
      "2021-10-12 11:33:12.086471 - ➕ Schema etalab/schema-decp-dpa added to config file.\n",
      "2021-10-12 11:33:12.089580 - ➕ Schema scdl/catalogue added to config file.\n",
      "2021-10-12 11:33:12.093504 - ➕ Schema scdl/deliberations added to config file.\n",
      "2021-10-12 11:33:12.098057 - ➕ Schema scdl/equipements added to config file.\n",
      "2021-10-12 11:33:12.103162 - ➕ Schema scdl/subventions added to config file.\n",
      "2021-10-12 11:33:12.108428 - ➕ Schema etalab/schema-lieux-covoiturage added to config file.\n",
      "2021-10-12 11:33:12.116059 - ➕ Schema etalab/schema-stationnement added to config file.\n",
      "2021-10-12 11:33:12.122573 - ➕ Schema scdl/budget added to config file.\n",
      "2021-10-12 11:33:12.129503 - ➕ Schema arsante/schema-dae added to config file.\n",
      "2021-10-12 11:33:12.137279 - ➕ Schema NaturalSolutions/schema-arbre added to config file.\n",
      "2021-10-12 11:33:12.146001 - ➕ Schema etalab/schema-stationnement-cyclable added to config file.\n",
      "2021-10-12 11:33:12.156157 - ➕ Schema etalab/schema-inclusion-numerique added to config file.\n",
      "2021-10-12 11:33:12.166726 - ➕ Schema etalab/schema-hautes-remunerations added to config file.\n",
      "2021-10-12 11:33:12.177874 - ➕ Schema scdl/menus-collectifs added to config file.\n",
      "2021-10-12 11:33:12.189861 - ➕ Schema scdl/plats-menus-collectifs added to config file.\n",
      "2021-10-12 11:33:12.203089 - ➕ Schema MTES-MCT/acceslibre-schema added to config file.\n",
      "2021-10-12 11:33:12.215994 - ➕ Schema etalab/schema-sdirve added to config file.\n",
      "2021-10-12 11:33:12.229563 - ➕ Schema Archivistes75/registre_entrees added to config file.\n",
      "2021-10-12 11:33:12.244491 - ➕ Schema CEREMA/schema-arrete-circulation-marchandises added to config file.\n",
      "2021-10-12 11:33:12.260459 - ➕ Schema openmaraude/schema-stationstaxi added to config file.\n",
      "2021-10-12 11:33:12.277098 - ➕ Schema etalab/schema-vehicules-faibles-emissions-renouvellement-parc added to config file.\n",
      "2021-10-12 11:33:12.294591 - ➕ Schema datakode/schema-pei added to config file.\n",
      "2021-10-12 11:33:12.311670 - ➕ Schema etalab/schema-passage-a-niveau added to config file.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(config_path) :\n",
    "    with open(config_path, 'r') as f :\n",
    "        config_dict = yaml.safe_load(f)\n",
    "else :\n",
    "    config_dict = {}\n",
    "    \n",
    "for schema in schemas_catalogue_list :\n",
    "    if schema['name'] not in config_dict.keys() :\n",
    "        add_schema_default_config(schema['name'], config_path)\n",
    "        schemas_report_dict[schema['name']]['new_config_created'] = True\n",
    "        print('{} - ➕ Schema {} added to config file.'.format(datetime.today(), schema['name']))\n",
    "    else :\n",
    "        schemas_report_dict[schema['name']]['new_config_created'] = False\n",
    "        print('{} - 🆗 Schema {} already in config file.'.format(datetime.today(), schema['name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**⚠️⚠️⚠️ EDIT CONFIG FILE IF NEEDED (especially for new schemas) ⚠️⚠️⚠️**\n",
    "\n",
    "Then, reload config file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config_path, 'r') as f :\n",
    "    config_dict = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building reference tables (parsing and listing resources + Validata check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-12 11:47:51.100094 - ℹ️ STARTING SCHEMA: Archivistes75/registre_entrees\n",
      "2021-10-12 11:47:51.100312 -- ❌ Schema not to consolidate according to config file.\n",
      "2021-10-12 11:47:51.100342 - ℹ️ STARTING SCHEMA: CEREMA/schema-arrete-circulation-marchandises\n",
      "2021-10-12 11:47:51.100362 -- ❌ Schema not to consolidate according to config file.\n",
      "2021-10-12 11:47:51.100382 - ℹ️ STARTING SCHEMA: MTES-MCT/acceslibre-schema\n",
      "2021-10-12 11:47:51.100400 -- ❌ Schema not to consolidate according to config file.\n",
      "2021-10-12 11:47:51.100414 - ℹ️ STARTING SCHEMA: NaturalSolutions/schema-arbre\n",
      "2021-10-12 11:47:51.100446 -- ❌ Schema not to consolidate according to config file.\n",
      "2021-10-12 11:47:51.100499 - ℹ️ STARTING SCHEMA: arsante/schema-dae\n",
      "2021-10-12 11:47:51.100531 -- ❌ Schema not to consolidate according to config file.\n",
      "2021-10-12 11:47:51.100560 - ℹ️ STARTING SCHEMA: datakode/schema-pei\n",
      "2021-10-12 11:47:51.100582 -- ❌ Schema not to consolidate according to config file.\n",
      "2021-10-12 11:47:51.100597 - ℹ️ STARTING SCHEMA: etalab/schema-decp-dpa\n",
      "2021-10-12 11:47:51.100614 -- ❌ Schema not to consolidate according to config file.\n",
      "2021-10-12 11:47:51.100632 - ℹ️ STARTING SCHEMA: etalab/schema-hautes-remunerations\n",
      "2021-10-12 11:47:51.100647 -- ❌ Schema not to consolidate according to config file.\n",
      "2021-10-12 11:47:51.100661 - ℹ️ STARTING SCHEMA: etalab/schema-inclusion-numerique\n",
      "2021-10-12 11:47:51.100686 -- ❌ Schema not to consolidate according to config file.\n",
      "2021-10-12 11:47:51.100701 - ℹ️ STARTING SCHEMA: etalab/schema-irve\n",
      "2021-10-12 11:48:31.298322 -- 🔢 513 resource(s) found for this schema.\n",
      "2021-10-12 11:48:31.298480 --- ❌ Version 1.0.0 to drop according to config file\n",
      "2021-10-12 11:48:31.298514 --- ❌ Version 1.0.1 to drop according to config file\n",
      "2021-10-12 11:48:31.298531 --- ❌ Version 1.0.2 to drop according to config file\n",
      "2021-10-12 11:48:31.298546 --- ❌ Version 1.0.3 to drop according to config file\n",
      "2021-10-12 11:48:31.298564 --- ❌ Version 2.0.0 to drop according to config file\n",
      "2021-10-12 11:48:31.298581 --- ❌ Version 2.0.1 to drop according to config file\n",
      "2021-10-12 11:49:57.684947 ---- 🔴 No info in validata report for resource: https://static.data.gouv.fr/resources/irve-sied70-recensement-et-information/20190228-173321/irve-sied70-20190228.csv (ERROR MESSAGE: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.)\n",
      "2021-10-12 11:51:01.993247 ---- 🔴 No info in validata report for resource: https://static.data.gouv.fr/resources/premier-export-irve-zeborne-mobility-services-fev2021/20210211-153735/export-irve-data-gouv-v1-11fev21.csv (ERROR MESSAGE: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.)\n",
      "2021-10-12 11:51:55.690375 ---- 🔴 No info in validata report for resource: https://static.data.gouv.fr/resources/caracteristiques-des-points-de-charge-pour-vehicules-electriques-electric-55-charging-ouverts-au-public/20200814-151629/irve-e55c-ajourle.14.08.20.csv (ERROR MESSAGE: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.)\n",
      "2021-10-12 11:52:36.241596 ---- 🔴 No info in validata report for resource: https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-26/20210913-143231/bornes-rse01.csv (ERROR MESSAGE: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.)\n",
      "2021-10-12 11:54:49.081792 ---- 🔴 No info in validata report for resource: https://opendata.paris.fr/explore/dataset/paris-recharge-points-de-recharge-pour-vehicules-electriques-donnees-statiques/download?format=csv&timezone=Europe/Berlin&use_labels_for_header=false (ERROR MESSAGE: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.)\n",
      "2021-10-12 11:55:33.078815 ---- 🔴 No info in validata report for resource: https://sdem.opendatasoft.com/explore/dataset/25560110600024_bornes-de-recharge-de-vehicules-electriques-irve/download?format=csv&timezone=Europe/Berlin&use_labels_for_header=false (ERROR MESSAGE: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.)\n",
      "2021-10-12 11:55:55.076030 ---- 🔴 No info in validata report for resource: https://data.seineouest.fr/explore/dataset/reseau-de-bornes-de-recharge-pour-vehicule-electrique/download?format=csv&timezone=Europe/Berlin&use_labels_for_header=false (ERROR MESSAGE: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.)\n",
      "2021-10-12 11:56:47.614146 ---- 🔴 No info in validata report for resource: https://data.orleans-metropole.fr/explore/dataset/irve-alize-liberte-orleans-metropole/download?format=csv&timezone=Europe/Berlin&use_labels_for_header=false (ERROR MESSAGE: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.)\n",
      "2021-10-12 11:57:51.562531 ---- 🔴 No info in validata report for resource: https://gpseo.opendatasoft.com/explore/dataset/infrastructures_de_recharge_vehicules_electriques_epone/download?format=csv&timezone=Europe/Berlin&use_labels_for_header=false (ERROR MESSAGE: 500 Internal Server Error: The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.)\n",
      "2021-10-12 11:58:00.974508 --- ☑️ Validata check done for version 2.0.2\n",
      "2021-10-12 11:58:00.997626 -- ✅ Validata check done for etalab/schema-irve.\n",
      "2021-10-12 11:58:00.997762 - ℹ️ STARTING SCHEMA: etalab/schema-lieux-covoiturage\n",
      "2021-10-12 11:58:00.997805 -- ❌ Schema not to consolidate according to config file.\n",
      "2021-10-12 11:58:00.997827 - ℹ️ STARTING SCHEMA: etalab/schema-passage-a-niveau\n",
      "2021-10-12 11:58:00.997843 -- ❌ Schema not to consolidate according to config file.\n",
      "2021-10-12 11:58:00.997857 - ℹ️ STARTING SCHEMA: etalab/schema-sdirve\n",
      "2021-10-12 11:58:00.997875 -- ❌ Schema not to consolidate according to config file.\n",
      "2021-10-12 11:58:00.997893 - ℹ️ STARTING SCHEMA: etalab/schema-stationnement\n",
      "2021-10-12 11:58:00.997908 -- ❌ Schema not to consolidate according to config file.\n",
      "2021-10-12 11:58:00.997922 - ℹ️ STARTING SCHEMA: etalab/schema-stationnement-cyclable\n",
      "2021-10-12 11:58:00.997942 -- ❌ Schema not to consolidate according to config file.\n",
      "2021-10-12 11:58:00.997960 - ℹ️ STARTING SCHEMA: etalab/schema-vehicules-faibles-emissions-renouvellement-parc\n",
      "2021-10-12 11:58:00.997975 -- ❌ Schema not to consolidate according to config file.\n",
      "2021-10-12 11:58:00.997989 - ℹ️ STARTING SCHEMA: openmaraude/schema-stationstaxi\n",
      "2021-10-12 11:58:00.998043 -- ❌ Schema not to consolidate according to config file.\n",
      "2021-10-12 11:58:00.998074 - ℹ️ STARTING SCHEMA: scdl/budget\n",
      "2021-10-12 11:58:00.998094 -- ❌ Schema not to consolidate according to config file.\n",
      "2021-10-12 11:58:00.998113 - ℹ️ STARTING SCHEMA: scdl/catalogue\n",
      "2021-10-12 11:58:00.998131 -- ❌ Schema not to consolidate according to config file.\n",
      "2021-10-12 11:58:00.998230 - ℹ️ STARTING SCHEMA: scdl/deliberations\n",
      "2021-10-12 11:58:00.998249 -- ❌ Schema not to consolidate according to config file.\n",
      "2021-10-12 11:58:00.998271 - ℹ️ STARTING SCHEMA: scdl/equipements\n",
      "2021-10-12 11:58:00.998289 -- ❌ Schema not to consolidate according to config file.\n",
      "2021-10-12 11:58:00.998303 - ℹ️ STARTING SCHEMA: scdl/menus-collectifs\n",
      "2021-10-12 11:58:00.998317 -- ❌ Schema not to consolidate according to config file.\n",
      "2021-10-12 11:58:00.998349 - ℹ️ STARTING SCHEMA: scdl/plats-menus-collectifs\n",
      "2021-10-12 11:58:00.998368 -- ❌ Schema not to consolidate according to config file.\n",
      "2021-10-12 11:58:00.998383 - ℹ️ STARTING SCHEMA: scdl/subventions\n",
      "2021-10-12 11:58:00.998432 -- ❌ Schema not to consolidate according to config file.\n",
      "CPU times: user 15.6 s, sys: 982 ms, total: 16.6 s\n",
      "Wall time: 10min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for schema_name in config_dict.keys() :\n",
    "    \n",
    "    print('{} - ℹ️ STARTING SCHEMA: {}'.format(datetime.now(), schema_name))\n",
    "    \n",
    "    #NEEDED PARAMETERS\n",
    "    \n",
    "    #Schema description and consolidation configuration\n",
    "    schema_config = config_dict[schema_name]\n",
    "    \n",
    "    if schema_config['consolidate'] == True :\n",
    "    \n",
    "        #Schema official specification (in catalogue)\n",
    "        schema_dict = get_schema_dict(schema_name, schemas_catalogue_list)\n",
    "\n",
    "        #Datasets to exclude (from config)\n",
    "        datasets_to_exclude = []\n",
    "        if 'consolidated_dataset_id' in schema_config.keys() :\n",
    "            datasets_to_exclude += [schema_config['consolidated_dataset_id']]\n",
    "        if 'exclude_dataset_ids' in schema_config.keys() :\n",
    "            if type(schema_config['exclude_dataset_ids']) == list :\n",
    "                datasets_to_exclude += schema_config['exclude_dataset_ids']\n",
    "\n",
    "        #Tags and search words to use to get resources that could match schema (from config)\n",
    "        tags_list = []\n",
    "        if 'tags' in schema_config.keys() :\n",
    "            tags_list += schema_config['tags']\n",
    "\n",
    "        search_words_list = []\n",
    "        if 'search_words' in schema_config.keys() :\n",
    "            search_words_list = schema_config['search_words']\n",
    "\n",
    "        #Schema versions not to consolidate\n",
    "        drop_versions = []\n",
    "        if 'drop_versions' in schema_config.keys() :\n",
    "            drop_versions += schema_config['drop_versions']\n",
    "        \n",
    "        schemas_report_dict[schema_name]['nb_versions_to_drop_in_config'] = len(drop_versions)\n",
    "\n",
    "        #PARSING API TO GET ALL ELIGIBLE RESOURCES FOR CONSOLIDATION\n",
    "\n",
    "        df_list = []\n",
    "\n",
    "        #Listing resources by schema request\n",
    "        df_schema = parse_api(schema_url_base.format(schema_name=schema_name))\n",
    "        schemas_report_dict[schema_name]['nb_resources_found_by_schema'] = len(df_schema)\n",
    "        if len(df_schema) > 0 :\n",
    "            df_schema['resource_found_by'] = '1 - schema request'\n",
    "            df_schema['initial_version_name'] = df_schema.apply(lambda row : get_resource_schema_version(row, api_url), axis=1)\n",
    "            df_list += [df_schema]\n",
    "\n",
    "        #Listing resources by tag requests\n",
    "        schemas_report_dict[schema_name]['nb_resources_found_by_tags'] = 0\n",
    "        for tag in tags_list : \n",
    "            df_tag = parse_api(tag_url_base.format(tag=tag))\n",
    "            schemas_report_dict[schema_name]['nb_resources_found_by_tags'] += len(df_tag)\n",
    "            if len(df_tag) > 0 :\n",
    "                df_tag['resource_found_by'] = '2 - tag request'\n",
    "                df_list += [df_tag]\n",
    "\n",
    "        #Listing resources by search (keywords) requests\n",
    "        schemas_report_dict[schema_name]['nb_resources_found_by_search_words'] = 0\n",
    "        for search_word in search_words_list :\n",
    "            df_search_word = parse_api(search_url_base.format(search_word=search_word))\n",
    "            schemas_report_dict[schema_name]['nb_resources_found_by_search_words'] += len(df_search_word)\n",
    "            if len(df_search_word) > 0 :\n",
    "                df_search_word['resource_found_by'] = '3 - search request'\n",
    "                df_list += [df_search_word]\n",
    "\n",
    "        if len(df_list) > 0 :\n",
    "            df = pd.concat(df_list, ignore_index=True)\n",
    "            df = df[~(df['dataset_id'].isin(datasets_to_exclude))]\n",
    "            df = df.sort_values('resource_found_by')\n",
    "            df = df.drop_duplicates(subset=['resource_id'], keep='first')\n",
    "            \n",
    "            print('{} -- 🔢 {} resource(s) found for this schema.'.format(datetime.now(), len(df)))\n",
    "            \n",
    "            if 'initial_version_name' not in df.columns : # in case there is no resource found by schema request\n",
    "                df['initial_version_name'] = np.nan\n",
    "\n",
    "            #FOR EACH RESOURCE AND SCHEMA VERSION, CHECK IF RESOURCE MATCHES THE SCHEMA VERSION\n",
    "\n",
    "            #Apply validata check for each version that is not explicitly dropped in config file\n",
    "            version_names_list = []\n",
    "            \n",
    "            for version in schema_dict['versions'] :\n",
    "                version_name = version['version_name']\n",
    "                if version_name not in drop_versions :\n",
    "                    schema_url = version['schema_url']\n",
    "                    df['is_valid_v_{}'.format(version_name)] = df.apply(lambda row : is_validata_valid_row(row, schema_url), axis=1)\n",
    "                    version_names_list += [version_name]\n",
    "                    print('{} --- ☑️ Validata check done for version {}'.format(datetime.now(), version_name))\n",
    "                else :\n",
    "                    print('{} --- ❌ Version {} to drop according to config file'.format(datetime.now(), version_name))\n",
    "            \n",
    "            if len(version_names_list) > 0 :\n",
    "                #Check if resources are at least matching one schema version (only those matching will be downloaded in next step)\n",
    "                df['is_valid_one_version'] = sum([df['is_valid_v_{}'.format(version_name)] for version_name in version_names_list]) > 0\n",
    "                schemas_report_dict[schema_name]['nb_valid_resources'] = df['is_valid_one_version'].sum()\n",
    "                df = add_most_recent_valid_version(df)\n",
    "                df.to_csv(os.path.join(ref_tables_path, 'ref_table_{}.csv'.format(schema_name.replace('/', '_'))), index=False)\n",
    "                print('{} -- ✅ Validata check done for {}.'.format(datetime.now(), schema_name))\n",
    "            else :\n",
    "                schemas_report_dict[schema_name]['nb_valid_resources'] = 0\n",
    "                print('{} -- ❌ All possible versions for this schema were dropped by config file.'.format(datetime.now()))\n",
    "\n",
    "        else :\n",
    "            print('{} -- ⚠️ No resource found for this schema.'.format(datetime.now(), schema_name))\n",
    "            \n",
    "    else :\n",
    "        print('{} -- ❌ Schema not to consolidate according to config file.'.format(datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading valid data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We download only data that is valid for at least one version of the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-12 12:00:20.180168 - ℹ️ STARTING SCHEMA: Archivistes75/registre_entrees\n",
      "2021-10-12 12:00:20.180532 -- ❌ No reference table made for this schema (schema not to consolidate, no version to consolidate or no resource found).\n",
      "2021-10-12 12:00:20.180579 - ℹ️ STARTING SCHEMA: CEREMA/schema-arrete-circulation-marchandises\n",
      "2021-10-12 12:00:20.180681 -- ❌ No reference table made for this schema (schema not to consolidate, no version to consolidate or no resource found).\n",
      "2021-10-12 12:00:20.180726 - ℹ️ STARTING SCHEMA: MTES-MCT/acceslibre-schema\n",
      "2021-10-12 12:00:20.180839 -- ❌ No reference table made for this schema (schema not to consolidate, no version to consolidate or no resource found).\n",
      "2021-10-12 12:00:20.180879 - ℹ️ STARTING SCHEMA: NaturalSolutions/schema-arbre\n",
      "2021-10-12 12:00:20.181017 -- ❌ No reference table made for this schema (schema not to consolidate, no version to consolidate or no resource found).\n",
      "2021-10-12 12:00:20.181069 - ℹ️ STARTING SCHEMA: arsante/schema-dae\n",
      "2021-10-12 12:00:20.181131 -- ❌ No reference table made for this schema (schema not to consolidate, no version to consolidate or no resource found).\n",
      "2021-10-12 12:00:20.181156 - ℹ️ STARTING SCHEMA: datakode/schema-pei\n",
      "2021-10-12 12:00:20.181383 -- ❌ No reference table made for this schema (schema not to consolidate, no version to consolidate or no resource found).\n",
      "2021-10-12 12:00:20.181433 - ℹ️ STARTING SCHEMA: etalab/schema-decp-dpa\n",
      "2021-10-12 12:00:20.181627 -- ❌ No reference table made for this schema (schema not to consolidate, no version to consolidate or no resource found).\n",
      "2021-10-12 12:00:20.181810 - ℹ️ STARTING SCHEMA: etalab/schema-hautes-remunerations\n",
      "2021-10-12 12:00:20.181999 -- ❌ No reference table made for this schema (schema not to consolidate, no version to consolidate or no resource found).\n",
      "2021-10-12 12:00:20.182041 - ℹ️ STARTING SCHEMA: etalab/schema-inclusion-numerique\n",
      "2021-10-12 12:00:20.182106 -- ❌ No reference table made for this schema (schema not to consolidate, no version to consolidate or no resource found).\n",
      "2021-10-12 12:00:20.182135 - ℹ️ STARTING SCHEMA: etalab/schema-irve\n",
      "2021-10-12 12:00:20.313941 --- ⬇️✅ downloaded file [irve-data.gouv.compagnie-des-ports-morbihan.csv] https://static.data.gouv.fr/resources/infrastructures-de-recharge-en-itinerance-publique-1/20211001-171313/irve-data.gouv.compagnie-des-ports-morbihan.csv\n",
      "2021-10-12 12:00:20.464846 --- ⬇️✅ downloaded file [Monfichier_NF050499] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-charge-rapide-5/20210730-141601/data.csv\n",
      "2021-10-12 12:00:20.617505 --- ⬇️✅ downloaded file [Monfichier_NF078238] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-charge-rapide-5/20210730-142326/data.csv\n",
      "2021-10-12 12:00:20.753240 --- ⬇️✅ downloaded file [Monfichier_NF068069] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-charge-rapide-5/20210730-143103/data.csv\n",
      "2021-10-12 12:00:20.906869 --- ⬇️✅ downloaded file [Monfichier_NF068069] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-charge-rapide-5/20210730-143104/data.csv\n",
      "2021-10-12 12:00:20.985102 --- ⬇️✅ downloaded file [Monfichier_NF080183] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-charge-rapide-5/20210730-144547/data.csv\n",
      "2021-10-12 12:00:21.087038 --- ⬇️✅ downloaded file [Monfichier_NF039295] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-charge-rapide-5/20210730-145157/data.csv\n",
      "2021-10-12 12:00:21.197261 --- ⬇️✅ downloaded file [Monfichier_NF001019] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-charge-rapide-5/20210923-105802/data.csv\n",
      "2021-10-12 12:00:21.293059 --- ⬇️✅ downloaded file [Bornes IRVE Bulle de Linge] https://static.data.gouv.fr/resources/bornes-irve-bulle-de-linge/20210810-005110/bulle-de-linge-irve.csv\n",
      "2021-10-12 12:00:21.410772 --- ⬇️✅ downloaded file [Monfichier_NF080162] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-charge-rapide-5/20210715-160304/data.csv\n",
      "2021-10-12 12:00:21.558955 --- ⬇️✅ downloaded file [Bornes IRVE Syndicat Intercommunal d'Electricité et de Gaz de l'Eure] https://static.data.gouv.fr/resources/bornes-irve-syndicat-intercommunal-delectricite-et-de-gaz-de-leure/20210629-184259/irve-siege27-20200113.xlsx-irve-siege27-new-format-20210610-.csv\n",
      "2021-10-12 12:00:21.692394 --- ⬇️✅ downloaded file [CSV Data.gouv Hotel Macon] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-inouid-smart-mobility/20210730-164241/data.csv\n",
      "2021-10-12 12:00:21.869236 --- ⬇️✅ downloaded file [HotelMacon.csv] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-inouid-smart-mobility/20210730-165005/data.csv\n",
      "2021-10-12 12:00:21.998949 --- ⬇️✅ downloaded file [SERTITUDE] https://static.data.gouv.fr/resources/sertitude-1/20210622-154629/data.csv\n",
      "2021-10-12 12:00:22.114000 --- ⬇️✅ downloaded file [GARAGE ZAWIEJA] https://static.data.gouv.fr/resources/garage-zawieja/20210624-143905/data.csv\n",
      "2021-10-12 12:00:22.220937 --- ⬇️✅ downloaded file [Fichier IRVE Borne Leclerc Marmande] https://static.data.gouv.fr/resources/e-leclerc-marmande/20210615-105609/data.csv\n",
      "2021-10-12 12:00:22.328950 --- ⬇️✅ downloaded file [irve-tente-20210525.csv] https://static.data.gouv.fr/resources/irve-tente/20210713-152818/irve-tente-20210525.csv\n",
      "2021-10-12 12:00:22.438680 --- ⬇️✅ downloaded file [Monfichier] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-charge-rapide/20210715-120952/data.csv\n",
      "2021-10-12 12:00:22.566828 --- ⬇️✅ downloaded file [Monfichier_NF007060] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-charge-rapide/20210715-122351/data.csv\n",
      "2021-10-12 12:00:22.663974 --- ⬇️✅ downloaded file [Monfichier_NF010132] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-charge-rapide/20210715-140046/data.csv\n",
      "2021-10-12 12:00:22.766828 --- ⬇️✅ downloaded file [Monfichier_NF050462] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-charge-rapide/20210715-141656/data.csv\n",
      "2021-10-12 12:00:22.856705 --- ⬇️✅ downloaded file [Monfichier_NF058543] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-charge-rapide/20210715-145347/data.csv\n",
      "2021-10-12 12:00:22.962277 --- ⬇️✅ downloaded file [Monfichier_NF078171] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-charge-rapide-4/20210715-154841/data.csv\n",
      "2021-10-12 12:00:23.083593 --- ⬇️✅ downloaded file [Monfichier_NF077241] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-charge-rapide-4/20210730-144039/data.csv\n",
      "2021-10-12 12:00:23.219048 --- ⬇️✅ downloaded file [Monfichier] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-21/20210715-201203/data.csv\n",
      "2021-10-12 12:00:23.340670 --- ⬇️✅ downloaded file [irve-mobisdec-20210823.csv] https://static.data.gouv.fr/resources/bornes-de-recharge-mobisdec-syndicat-departemental-denergies-du-calvados/20210823-145421/irve-mobisdec-20210823.csv\n",
      "2021-10-12 12:00:23.462239 --- ⬇️✅ downloaded file [Infrastructures de recharge pour véhicules électriques (organisation MEA ENERGIES)] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-mea-energies/20210806-163155/data.csv\n",
      "2021-10-12 12:00:23.570392 --- ⬇️✅ downloaded file [Monfichier_NF059786] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-charge-rapide-1/20210715-151612/data.csv\n",
      "2021-10-12 12:00:23.686305 --- ⬇️✅ downloaded file [IRVE_sdesm_20210609.csv] https://static.data.gouv.fr/resources/bornes-de-recharges-ecocharge77/20210609-175423/data.csv\n",
      "2021-10-12 12:00:23.776333 --- ⬇️✅ downloaded file [SAS-Sabo.CVS] https://static.data.gouv.fr/resources/borne-de-recharge-de-la-sas-sabo/20210517-162554/data.csv\n",
      "2021-10-12 12:00:23.909044 --- ⬇️✅ downloaded file [Monfichier] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-21/20210715-201201/data.csv\n",
      "2021-10-12 12:00:23.968793 --- ⬇️✅ downloaded file [Monfichier] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-21/20210715-201201/data.csv\n",
      "2021-10-12 12:00:24.079867 --- ⬇️✅ downloaded file [Monfichier] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-21/20210715-201200/data.csv\n",
      "2021-10-12 12:00:24.179617 --- ⬇️✅ downloaded file [Electriox Groupe IRVE Genay] https://static.data.gouv.fr/resources/electriox-groupe-irve-genay/20210618-173918/data.csv\n",
      "2021-10-12 12:00:24.307069 --- ⬇️✅ downloaded file [AVOMARKS] https://static.data.gouv.fr/resources/mes-bornes/20210623-181651/data.csv\n",
      "2021-10-12 12:00:24.452032 --- ⬇️✅ downloaded file [BBJ.csv] https://static.data.gouv.fr/resources/borne-de-recharge-1/20210518-121750/data.csv\n",
      "2021-10-12 12:00:24.557173 --- ⬇️✅ downloaded file [Leclerc Mimizan.csv] https://static.data.gouv.fr/resources/borne-de-recharge-1/20210518-150007/data.csv\n",
      "2021-10-12 12:00:24.666614 --- ⬇️✅ downloaded file [Leclerc Express Labouheyre.csv] https://static.data.gouv.fr/resources/borne-de-recharge-1/20210518-161537/data.csv\n",
      "2021-10-12 12:00:24.754673 --- ⬇️✅ downloaded file [Centre Auto Leclerc Langon] https://static.data.gouv.fr/resources/borne-de-recharge-1/20210719-175333/data.csv\n",
      "2021-10-12 12:00:24.856769 --- ⬇️✅ downloaded file [Leclerc Biars] https://static.data.gouv.fr/resources/borne-de-recharge-1/20210730-113648/data.csv\n",
      "2021-10-12 12:00:24.979042 --- ⬇️✅ downloaded file [Leclerc Mios] https://static.data.gouv.fr/resources/borne-de-recharge-1/20210802-103955/data.csv\n",
      "2021-10-12 12:00:25.082422 --- ⬇️✅ downloaded file [SAS Lujasy] https://static.data.gouv.fr/resources/borne-de-recharge-de-la-sas-lujasy/20210630-130817/data.csv\n",
      "2021-10-12 12:00:25.204267 --- ⬇️✅ downloaded file [Hôtel Macchi] https://static.data.gouv.fr/resources/borne-de-recharge-de-lhotel-macchi/20210630-130047/data.csv\n",
      "2021-10-12 12:00:25.287649 --- ⬇️✅ downloaded file [bornes-irve-sogestran.csv] https://static.data.gouv.fr/resources/bornes-irve-sogestran/20210721-111132/bornes-irve-sogestran.csv\n",
      "2021-10-12 12:00:25.399555 --- ⬇️✅ downloaded file [Monfichier_NF076523] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-charge-rapide-2/20210715-152527/data.csv\n",
      "2021-10-12 12:00:25.501090 --- ⬇️✅ downloaded file [irve-de-lepervanche-jardins-de-la-sud-20210802.csv] https://static.data.gouv.fr/resources/les-jardins-de-la-sud/20210802-115644/irve-de-lepervanche-jardins-de-la-sud-20210802.csv\n",
      "2021-10-12 12:00:25.587638 --- ⬇️✅ downloaded file [datagouvhotelstwalfrid.csv] https://static.data.gouv.fr/resources/borne-de-charge-hotel-saint-walfrid/20210609-160233/data.csv\n",
      "2021-10-12 12:00:25.681268 --- ⬇️✅ downloaded file [SAP LABS FRANCE] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-abe-electricite/20210704-223716/data.csv\n",
      "2021-10-12 12:00:25.780217 --- ⬇️✅ downloaded file [etalab-schema-irve-2021-05-10t18-35-31.014z.csv] https://static.data.gouv.fr/resources/borne-recharge-hotel-la-javotte/20210510-210129/etalab-schema-irve-2021-05-10t18-35-31.014z.csv\n",
      "2021-10-12 12:00:25.864627 --- ⬇️✅ downloaded file [Borne de charge IRVE ALU GRANON] https://static.data.gouv.fr/resources/installation-de-bornes-de-recharges-sur-cavaillon/20210617-144920/data.csv\n",
      "2021-10-12 12:00:25.992065 --- ⬇️✅ downloaded file [Monfichier] https://static.data.gouv.fr/resources/installation-de-bornes-de-recharges-sur-cavaillon/20210810-151828/data.csv\n",
      "2021-10-12 12:00:26.066559 --- ⬇️✅ downloaded file [PERRUT] https://static.data.gouv.fr/resources/installation-de-bornes-de-recharges-sur-cavaillon/20211007-151135/data.csv\n",
      "2021-10-12 12:00:26.171852 --- ⬇️✅ downloaded file [AEV-SATORIZ GRENOBLE ROCADE-DATA.GOUV] https://static.data.gouv.fr/resources/satoriz-grenoble-rocde/20210802-073357/data.csv\n",
      "2021-10-12 12:00:26.298598 --- ⬇️✅ downloaded file [DATA GOUV - Borne de recharge Coprodex Saint-Avold] https://static.data.gouv.fr/resources/borne-de-recharge-coprodex-saint-avold/20210622-133631/data.csv\n",
      "2021-10-12 12:00:26.448406 --- ⬇️✅ downloaded file [ETANCHEITE PARTICULIERS ET INDUSTRIES] https://static.data.gouv.fr/resources/etancheite-particuliers-et-industries/20210622-164547/data.csv\n",
      "2021-10-12 12:00:26.582027 --- ⬇️✅ downloaded file [Bornes_Rossini_20-7-21] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-rossini-energy/20210720-155831/data.csv\n",
      "2021-10-12 12:00:26.694989 --- ⬇️✅ downloaded file [Bornes-Rossini-11/10/21] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-rossini-energy/20211011-163305/data.csv\n",
      "2021-10-12 12:00:26.835331 --- ⬇️✅ downloaded file [Monfichier] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-1/20210712-185003/data.csv\n",
      "2021-10-12 12:00:26.964685 --- ⬇️✅ downloaded file [Monfichier.csv] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-22/20210723-133435/data.csv\n",
      "2021-10-12 12:00:27.075501 --- ⬇️✅ downloaded file [Monfichier.csv] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-22/20210721-162941/data.csv\n",
      "2021-10-12 12:00:27.183951 --- ⬇️✅ downloaded file [F3C Baume DATA GOUV] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-properphi/20210719-130807/data.csv\n",
      "2021-10-12 12:00:27.301894 --- ⬇️✅ downloaded file [AQUA LOISIRS XEV200C] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-infelec/20210705-160322/data.csv\n",
      "2021-10-12 12:00:27.403116 --- ⬇️✅ downloaded file [SV data.gouv quincy.csv] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-23/20210729-220255/data.csv\n",
      "2021-10-12 12:00:27.498273 --- ⬇️✅ downloaded file [FXM EVENTS] https://static.data.gouv.fr/resources/fxm-events/20210803-141049/data.csv\n",
      "2021-10-12 12:00:27.585411 --- ⬇️✅ downloaded file [Monfichier_NF059964] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-charge-rapide-3/20210715-154202/data.csv\n",
      "2021-10-12 12:00:27.681216 --- ⬇️✅ downloaded file [liste publique places 12 06 2021.csv] https://static.data.gouv.fr/resources/liste-place-de-recharge/20210612-152004/data.csv\n",
      "2021-10-12 12:00:27.789109 --- ⬇️✅ downloaded file [Monfichier IRVE Leclerc Drive Anglet] https://static.data.gouv.fr/resources/e-leclerc-drive-anglet/20210615-121154/data.csv\n",
      "2021-10-12 12:00:27.887352 --- ⬇️✅ downloaded file [LA FERME DE LA MOTTE] https://static.data.gouv.fr/resources/la-ferme-de-la-motte/20210622-162055/data.csv\n",
      "2021-10-12 12:00:27.996814 --- ⬇️✅ downloaded file [SDIRVE SDE23] https://static.data.gouv.fr/resources/bornes-sde-creuse/20210621-101944/data.csv\n",
      "2021-10-12 12:00:28.141310 --- ⬇️✅ downloaded file [irve-overchem-20210628.csv] https://static.data.gouv.fr/resources/overchem/20210713-153305/irve-overchem-20210628.csv\n",
      "2021-10-12 12:00:28.244961 --- ⬇️✅ downloaded file [Bornes de recharges GAMBUS et PHA] https://static.data.gouv.fr/resources/installation-de-bornes-de-recharges-sur-cavaillon/20210511-160232/data.csv\n",
      "2021-10-12 12:00:28.342868 --- ⬇️✅ downloaded file [RENAULT HAZEBROUCK] https://static.data.gouv.fr/resources/renault-hazebrouck/20211011-140043/data.csv\n",
      "2021-10-12 12:00:28.445197 --- ⬇️✅ downloaded file [Bornes IRVE Brasserie Castelain] https://static.data.gouv.fr/resources/bornes-irve-brasserie-castelain/20211004-140304/data-gouv-irve-2021-09-17.csv\n",
      "2021-10-12 12:00:28.557548 --- ⬇️✅ downloaded file [SOLLIX] https://static.data.gouv.fr/resources/sollix/20211008-095850/data.csv\n",
      "2021-10-12 12:00:28.710962 --- ⬇️✅ downloaded file [DATAGOUV CSV F3C ALBON.csv] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-properphi-1/20210809-122755/data.csv\n",
      "2021-10-12 12:00:28.842206 --- ⬇️✅ downloaded file [parc_mobive_33_2021_10_08] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-syndicat-departemental-denergie-electrique-de-la-gironde/20211008-173904/data.csv\n",
      "2021-10-12 12:00:28.952013 --- ⬇️✅ downloaded file [Infrastructures de recharge pour véhicules électriques (organisation MEA ENERGIES)] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-mea-energies-1/20210921-140138/data.csv\n",
      "2021-10-12 12:00:29.045831 --- ⬇️✅ downloaded file [ANS COM] https://static.data.gouv.fr/resources/ans-com/20210901-091115/data.csv\n",
      "2021-10-12 12:00:29.168200 --- ⬇️✅ downloaded file [GOOD KING] https://static.data.gouv.fr/resources/good-king/20210906-173433/data.csv\n",
      "2021-10-12 12:00:29.269103 --- ⬇️✅ downloaded file [ZEENCO] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-zeenco/20210920-123706/data.csv\n",
      "2021-10-12 12:00:29.473038 --- ⬇️✅ downloaded file [Monfichier] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-zeenco/20210923-181126/data.csv\n",
      "2021-10-12 12:00:29.621540 --- ⬇️✅ downloaded file [Monfichier] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-zeenco/20210924-123141/data.csv\n",
      "2021-10-12 12:00:29.767998 --- ⬇️✅ downloaded file [Fasthôtel Toulouse - Blagnac aéroport] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-autorecharge-1/20210820-180625/data.csv\n",
      "2021-10-12 12:00:29.885884 --- ⬇️✅ downloaded file [Monfichier.csv] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-waat/20210805-111910/data.csv\n",
      "2021-10-12 12:00:29.986053 --- ⬇️✅ downloaded file [STATIONS-E BORNES IRVE] https://static.data.gouv.fr/resources/stations-e-bornes-charge-irve/20211008-171639/data.csv\n",
      "2021-10-12 12:00:30.083685 --- ⬇️✅ downloaded file [EGSM] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-egsm/20210805-100406/data.csv\n",
      "2021-10-12 12:00:30.272534 --- ⬇️✅ downloaded file [irve-wiiiz-20211006.csv] https://static.data.gouv.fr/resources/bornes-de-recharges-wiiiz/20211006-121110/irve-wiiiz-20211006.csv\n",
      "2021-10-12 12:00:30.374465 --- ⬇️✅ downloaded file [irve_accor_louvre_hotels.csv] https://static.data.gouv.fr/resources/bornes-de-recharge-pour-vehicules-electriques-accor-hotels-et-louvre-hotels-group/20210924-121114/data.csv\n",
      "2021-10-12 12:00:30.502749 --- ⬇️✅ downloaded file [irve-sdem50-20210924.csv] https://static.data.gouv.fr/resources/e-charge50/20210926-123535/irve-sdem50-20210924.csv\n",
      "2021-10-12 12:00:30.596140 --- ⬇️✅ downloaded file [Monfichier] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-eco-pi-sas/20210916-112602/data.csv\n",
      "2021-10-12 12:00:30.715957 --- ⬇️✅ downloaded file [Monfichier.csv.csv] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-spie-citynetworks/20210921-152744/data.csv\n",
      "2021-10-12 12:00:30.860731 --- ⬇️✅ downloaded file [Monfichier] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-26/20210913-143141/data.csv\n",
      "2021-10-12 12:00:30.990654 --- ⬇️✅ downloaded file [2F Production] https://static.data.gouv.fr/resources/irve-2f-production/20210923-084311/data.csv\n",
      "2021-10-12 12:00:31.127160 --- ⬇️✅ downloaded file [Bornes IRVE L2B] https://static.data.gouv.fr/resources/bornes-irve-l2b/20211004-140138/datagouv-irve-2021-10-04.csv\n",
      "2021-10-12 12:00:31.242536 --- ⬇️✅ downloaded file [STBM] https://static.data.gouv.fr/resources/stbm/20210908-103504/data.csv\n",
      "2021-10-12 12:00:31.471944 --- ⬇️✅ downloaded file [BDS MENUISERIE] https://static.data.gouv.fr/resources/bds-menuiserie/20210902-142943/data.csv\n",
      "2021-10-12 12:00:31.589244 --- ⬇️✅ downloaded file [LE DOMAINE DES CIGOGNES] https://static.data.gouv.fr/resources/le-domaine-des-cigognes/20210903-095840/data.csv\n",
      "2021-10-12 12:00:31.707772 --- ⬇️✅ downloaded file [Monfichier] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-car2plug/20210812-174726/data.csv\n",
      "2021-10-12 12:00:31.809506 --- ⬇️✅ downloaded file [Monfichier] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-car2plug/20210830-150208/data.csv\n",
      "2021-10-12 12:00:31.904638 --- ⬇️✅ downloaded file [Monfichier.csv] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-autorecharge/20210809-103558/data.csv\n",
      "2021-10-12 12:00:31.989726 --- ⬇️✅ downloaded file [data-1-.csv] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-waat/20210930-115615/data-1-.csv\n",
      "2021-10-12 12:00:32.080266 --- ⬇️✅ downloaded file [Bornes IRVE DEBELEC] https://static.data.gouv.fr/resources/bornes-irve-debelec/20211004-142359/datagouv-irve-debelec-2021-10-04-feuille-1.csv\n",
      "2021-10-12 12:00:32.188179 --- ⬇️✅ downloaded file [adam.csv] https://static.data.gouv.fr/resources/bornes-de-charge-adam-sas/20210926-193632/adam.csv\n",
      "2021-10-12 12:00:32.328312 --- ⬇️✅ downloaded file [irve-data.gouv.incroyable.csv] https://static.data.gouv.fr/resources/infrastructures-de-recharge-en-itinerance-publique-1/20211001-122717/irve-data.gouv.incroyable.csv\n",
      "2021-10-12 12:00:32.422583 --- ⬇️✅ downloaded file [irve-data.gouv.odyssea.csv] https://static.data.gouv.fr/resources/infrastructures-de-recharge-en-itinerance-publique-1/20211001-122921/irve-data.gouv.odyssea.csv\n",
      "2021-10-12 12:00:32.526826 --- ⬇️✅ downloaded file [irve-data.gouv.uplink.angers.csv] https://static.data.gouv.fr/resources/infrastructures-de-recharge-en-itinerance-publique-1/20211001-143725/data.csv\n",
      "2021-10-12 12:00:32.612165 --- ⬇️✅ downloaded file [irve-data.gouv.dlj.conterie.csv] https://static.data.gouv.fr/resources/infrastructures-de-recharge-en-itinerance-publique-1/20211001-152239/irve-data.gouv.dlj.conterie.csv\n",
      "2021-10-12 12:00:32.723317 --- ⬇️✅ downloaded file [irve-data.gouv.illicoreseau.angers.csv] https://static.data.gouv.fr/resources/infrastructures-de-recharge-en-itinerance-publique-1/20211001-152353/irve-data.gouv.illicoreseau.angers.csv\n",
      "2021-10-12 12:00:32.915655 --- ⬇️✅ downloaded file [irve-data.gouv.bbraun.csv] https://static.data.gouv.fr/resources/infrastructures-de-recharge-en-itinerance-publique-1/20211001-152834/irve-data.gouv.bbraun.csv\n",
      "2021-10-12 12:00:33.021969 --- ⬇️✅ downloaded file [irve-data.gouv.tour.d.auvergne.csv] https://static.data.gouv.fr/resources/infrastructures-de-recharge-en-itinerance-publique-1/20211001-153913/irve-data.gouv.tour.d.auvergne.csv\n",
      "2021-10-12 12:00:33.121461 --- ⬇️✅ downloaded file [irve-data.gouv.sembreizh.csv] https://static.data.gouv.fr/resources/infrastructures-de-recharge-en-itinerance-publique-1/20211001-154503/irve-data.gouv.sembreizh.csv\n",
      "2021-10-12 12:00:33.231600 --- ⬇️✅ downloaded file [irve-data.gouv.dlj.st.gregoire.csv] https://static.data.gouv.fr/resources/infrastructures-de-recharge-en-itinerance-publique-1/20211001-160756/irve-data.gouv.dlj.st.gregoire.csv\n",
      "2021-10-12 12:00:33.390947 --- ⬇️✅ downloaded file [210830-irve-driveco.csv] https://static.data.gouv.fr/resources/liste-des-bornes-de-recharge-ouvertes-au-public/20210830-114846/210830-irve-driveco.csv\n",
      "2021-10-12 12:00:33.515448 --- ⬇️✅ downloaded file [irve-froth-20210924] https://static.data.gouv.fr/resources/bornes-de-recharges-reseau-froth/20210924-151526/data.csv\n",
      "2021-10-12 12:00:33.605965 --- ⬇️✅ downloaded file [Monfichier.csv] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-25/20210906-092711/data.csv\n",
      "2021-10-12 12:00:33.746877 --- ⬇️✅ downloaded file [JOUE LES TOURS.csv] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-herve-thermique-joue-les-tours/20210907-110957/data.csv\n",
      "2021-10-12 12:00:33.851397 --- ⬇️✅ downloaded file [LELIEUR FERNAND] https://static.data.gouv.fr/resources/lelieur-fernand/20211007-170746/data.csv\n",
      "2021-10-12 12:00:33.999993 --- ⬇️✅ downloaded file [Monfichier.csv] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-energie-eure-et-loir/20210923-164456/data.csv\n",
      "2021-10-12 12:00:34.091000 --- ⬇️✅ downloaded file [Monfichier durand etasse complete pour daltoner cherbourg (6).csv] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-sas-durand-etasse/20210929-215258/data.csv\n",
      "2021-10-12 12:00:34.250539 --- ⬇️✅ downloaded file [IRVE_SOREGIES_20210924.csv] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-soregies/20210924-194623/data.csv\n",
      "2021-10-12 12:00:34.342063 --- ⬇️✅ downloaded file [CHPY_Technopole] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-chargepoly-station-chpy-technopole/20211011-180620/data.csv\n",
      "2021-10-12 12:00:34.442199 --- ⬇️✅ downloaded file [2021-07-01-patrimoine-public-bs.csv] https://static.data.gouv.fr/resources/infrastructures-de-recharge-en-itinerance-publique/20210702-115957/2021-07-01-patrimoine-public-bs.csv\n",
      "2021-10-12 12:00:34.540449 --- ⬇️✅ downloaded file [Orchidées Data Gouv.csv] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-30/20211005-153912/data.csv\n",
      "2021-10-12 12:00:34.647072 --- ⬇️✅ downloaded file [reseau-e55c-etalab-v2-e55c.csv] https://static.data.gouv.fr/resources/reseau-electric-55-charging/20210618-134039/reseau-e55c-etalab-v2-e55c.csv\n",
      "2021-10-12 12:00:34.759099 --- ⬇️✅ downloaded file [IRVE_VIRTA_20210827.csv] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-organisation-virta/20210827-132629/data.csv\n",
      "2021-10-12 12:00:34.871636 --- ⬇️✅ downloaded file [irve-wiiiz-20211006.csv] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-irve/20211006-151405/irve-wiiiz-20211006.csv\n",
      "2021-10-12 12:00:34.988277 --- ⬇️✅ downloaded file [irve-wiiizcasa-20211006.csv] https://static.data.gouv.fr/resources/infrastructures-de-recharge-pour-vehicules-electriques-irve/20211006-155413/irve-wiiizcasa-20211006.csv\n",
      "2021-10-12 12:00:34.997666 - ℹ️ STARTING SCHEMA: etalab/schema-lieux-covoiturage\n",
      "2021-10-12 12:00:34.998034 -- ❌ No reference table made for this schema (schema not to consolidate, no version to consolidate or no resource found).\n",
      "2021-10-12 12:00:34.998078 - ℹ️ STARTING SCHEMA: etalab/schema-passage-a-niveau\n",
      "2021-10-12 12:00:34.998147 -- ❌ No reference table made for this schema (schema not to consolidate, no version to consolidate or no resource found).\n",
      "2021-10-12 12:00:34.998176 - ℹ️ STARTING SCHEMA: etalab/schema-sdirve\n",
      "2021-10-12 12:00:34.998226 -- ❌ No reference table made for this schema (schema not to consolidate, no version to consolidate or no resource found).\n",
      "2021-10-12 12:00:34.998254 - ℹ️ STARTING SCHEMA: etalab/schema-stationnement\n",
      "2021-10-12 12:00:34.998302 -- ❌ No reference table made for this schema (schema not to consolidate, no version to consolidate or no resource found).\n",
      "2021-10-12 12:00:34.998327 - ℹ️ STARTING SCHEMA: etalab/schema-stationnement-cyclable\n",
      "2021-10-12 12:00:34.998373 -- ❌ No reference table made for this schema (schema not to consolidate, no version to consolidate or no resource found).\n",
      "2021-10-12 12:00:34.998408 - ℹ️ STARTING SCHEMA: etalab/schema-vehicules-faibles-emissions-renouvellement-parc\n",
      "2021-10-12 12:00:34.998601 -- ❌ No reference table made for this schema (schema not to consolidate, no version to consolidate or no resource found).\n",
      "2021-10-12 12:00:34.998646 - ℹ️ STARTING SCHEMA: openmaraude/schema-stationstaxi\n",
      "2021-10-12 12:00:34.998711 -- ❌ No reference table made for this schema (schema not to consolidate, no version to consolidate or no resource found).\n",
      "2021-10-12 12:00:34.998738 - ℹ️ STARTING SCHEMA: scdl/budget\n",
      "2021-10-12 12:00:34.998914 -- ❌ No reference table made for this schema (schema not to consolidate, no version to consolidate or no resource found).\n",
      "2021-10-12 12:00:34.998942 - ℹ️ STARTING SCHEMA: scdl/catalogue\n",
      "2021-10-12 12:00:34.999115 -- ❌ No reference table made for this schema (schema not to consolidate, no version to consolidate or no resource found).\n",
      "2021-10-12 12:00:34.999260 - ℹ️ STARTING SCHEMA: scdl/deliberations\n",
      "2021-10-12 12:00:34.999488 -- ❌ No reference table made for this schema (schema not to consolidate, no version to consolidate or no resource found).\n",
      "2021-10-12 12:00:34.999532 - ℹ️ STARTING SCHEMA: scdl/equipements\n",
      "2021-10-12 12:00:34.999713 -- ❌ No reference table made for this schema (schema not to consolidate, no version to consolidate or no resource found).\n",
      "2021-10-12 12:00:34.999757 - ℹ️ STARTING SCHEMA: scdl/menus-collectifs\n",
      "2021-10-12 12:00:34.999903 -- ❌ No reference table made for this schema (schema not to consolidate, no version to consolidate or no resource found).\n",
      "2021-10-12 12:00:34.999935 - ℹ️ STARTING SCHEMA: scdl/plats-menus-collectifs\n",
      "2021-10-12 12:00:35.000065 -- ❌ No reference table made for this schema (schema not to consolidate, no version to consolidate or no resource found).\n",
      "2021-10-12 12:00:35.000094 - ℹ️ STARTING SCHEMA: scdl/subventions\n",
      "2021-10-12 12:00:35.000219 -- ❌ No reference table made for this schema (schema not to consolidate, no version to consolidate or no resource found).\n",
      "CPU times: user 2.04 s, sys: 191 ms, total: 2.23 s\n",
      "Wall time: 14.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for schema_name in config_dict.keys() :\n",
    "    \n",
    "    print('{} - ℹ️ STARTING SCHEMA: {}'.format(datetime.now(), schema_name))\n",
    "    \n",
    "    ref_table_path = os.path.join(ref_tables_path, 'ref_table_{}.csv'.format(schema_name.replace('/', '_')))\n",
    "    \n",
    "    if os.path.exists(ref_table_path) :\n",
    "        df_ref = pd.read_csv(ref_table_path)\n",
    "        df_ref['is_downloaded'] = False\n",
    "        \n",
    "        if len(df_ref[df_ref['is_valid_one_version'] == True]) > 0 :\n",
    "        \n",
    "            schema_data_path = Path(data_path) / schema_name.replace('/','_')\n",
    "            schema_data_path.mkdir(exist_ok=True)\n",
    "\n",
    "            for index,row in df_ref[df_ref['is_valid_one_version'] == True].iterrows():\n",
    "                rurl = row['resource_url']\n",
    "                r = requests.get(rurl, allow_redirects=True)\n",
    "                \n",
    "                if r.status_code == 200 :\n",
    "                    p = Path(schema_data_path) / row['dataset_slug']\n",
    "                    p.mkdir(exist_ok=True)\n",
    "                    written_filename = '{}.csv'.format(row['resource_id'])\n",
    "\n",
    "                    with open('{}/{}'.format(p, written_filename), 'wb') as f:\n",
    "                        f.write(r.content)\n",
    "                    \n",
    "                    df_ref.loc[(df_ref['resource_id'] == row['resource_id']), 'is_downloaded'] = True\n",
    "                    \n",
    "                    print('{} --- ⬇️✅ downloaded file [{}] {}'.format(datetime.now(), row['resource_title'], rurl))\n",
    "                else :\n",
    "                    print('{} --- ⬇️❌ File could not be downloaded: [{}] {}'.format(datetime.now(), row['resource_title'], rurl))\n",
    "                    \n",
    "        else :\n",
    "            print('{} -- ⚠️ No valid resource for this schema'.format(datetime.now()))\n",
    "            \n",
    "        df_ref.to_csv(ref_table_path, index=False)\n",
    "    \n",
    "    else :\n",
    "        print('{} -- ❌ No reference table made for this schema (schema not to consolidate, no version to consolidate or no resource found).'.format(datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consolidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-12 12:02:29.489711 - ℹ️ STARTING SCHEMA: Archivistes75/registre_entrees\n",
      "2021-10-12 12:02:29.490056 -- ❌ No data downloaded for this schema.\n",
      "2021-10-12 12:02:29.490085 - ℹ️ STARTING SCHEMA: CEREMA/schema-arrete-circulation-marchandises\n",
      "2021-10-12 12:02:29.490181 -- ❌ No data downloaded for this schema.\n",
      "2021-10-12 12:02:29.490207 - ℹ️ STARTING SCHEMA: MTES-MCT/acceslibre-schema\n",
      "2021-10-12 12:02:29.490317 -- ❌ No data downloaded for this schema.\n",
      "2021-10-12 12:02:29.490350 - ℹ️ STARTING SCHEMA: NaturalSolutions/schema-arbre\n",
      "2021-10-12 12:02:29.490450 -- ❌ No data downloaded for this schema.\n",
      "2021-10-12 12:02:29.490476 - ℹ️ STARTING SCHEMA: arsante/schema-dae\n",
      "2021-10-12 12:02:29.490620 -- ❌ No data downloaded for this schema.\n",
      "2021-10-12 12:02:29.490653 - ℹ️ STARTING SCHEMA: datakode/schema-pei\n",
      "2021-10-12 12:02:29.490729 -- ❌ No data downloaded for this schema.\n",
      "2021-10-12 12:02:29.490754 - ℹ️ STARTING SCHEMA: etalab/schema-decp-dpa\n",
      "2021-10-12 12:02:29.490958 -- ❌ No data downloaded for this schema.\n",
      "2021-10-12 12:02:29.490988 - ℹ️ STARTING SCHEMA: etalab/schema-hautes-remunerations\n",
      "2021-10-12 12:02:29.491092 -- ❌ No data downloaded for this schema.\n",
      "2021-10-12 12:02:29.491291 - ℹ️ STARTING SCHEMA: etalab/schema-inclusion-numerique\n",
      "2021-10-12 12:02:29.491374 -- ❌ No data downloaded for this schema.\n",
      "2021-10-12 12:02:29.491401 - ℹ️ STARTING SCHEMA: etalab/schema-irve\n",
      "2021-10-12 12:02:35.382575 -- ✅ DONE: etalab/schema-irve version 2.0.2\n",
      "2021-10-12 12:02:35.388551 - ℹ️ STARTING SCHEMA: etalab/schema-lieux-covoiturage\n",
      "2021-10-12 12:02:35.388692 -- ❌ No data downloaded for this schema.\n",
      "2021-10-12 12:02:35.388713 - ℹ️ STARTING SCHEMA: etalab/schema-passage-a-niveau\n",
      "2021-10-12 12:02:35.388766 -- ❌ No data downloaded for this schema.\n",
      "2021-10-12 12:02:35.388785 - ℹ️ STARTING SCHEMA: etalab/schema-sdirve\n",
      "2021-10-12 12:02:35.388830 -- ❌ No data downloaded for this schema.\n",
      "2021-10-12 12:02:35.388967 - ℹ️ STARTING SCHEMA: etalab/schema-stationnement\n",
      "2021-10-12 12:02:35.389077 -- ❌ No data downloaded for this schema.\n",
      "2021-10-12 12:02:35.389108 - ℹ️ STARTING SCHEMA: etalab/schema-stationnement-cyclable\n",
      "2021-10-12 12:02:35.389169 -- ❌ No data downloaded for this schema.\n",
      "2021-10-12 12:02:35.389190 - ℹ️ STARTING SCHEMA: etalab/schema-vehicules-faibles-emissions-renouvellement-parc\n",
      "2021-10-12 12:02:35.389238 -- ❌ No data downloaded for this schema.\n",
      "2021-10-12 12:02:35.389257 - ℹ️ STARTING SCHEMA: openmaraude/schema-stationstaxi\n",
      "2021-10-12 12:02:35.389412 -- ❌ No data downloaded for this schema.\n",
      "2021-10-12 12:02:35.389431 - ℹ️ STARTING SCHEMA: scdl/budget\n",
      "2021-10-12 12:02:35.389474 -- ❌ No data downloaded for this schema.\n",
      "2021-10-12 12:02:35.389492 - ℹ️ STARTING SCHEMA: scdl/catalogue\n",
      "2021-10-12 12:02:35.389534 -- ❌ No data downloaded for this schema.\n",
      "2021-10-12 12:02:35.389561 - ℹ️ STARTING SCHEMA: scdl/deliberations\n",
      "2021-10-12 12:02:35.389695 -- ❌ No data downloaded for this schema.\n",
      "2021-10-12 12:02:35.389716 - ℹ️ STARTING SCHEMA: scdl/equipements\n",
      "2021-10-12 12:02:35.389826 -- ❌ No data downloaded for this schema.\n",
      "2021-10-12 12:02:35.389847 - ℹ️ STARTING SCHEMA: scdl/menus-collectifs\n",
      "2021-10-12 12:02:35.389955 -- ❌ No data downloaded for this schema.\n",
      "2021-10-12 12:02:35.390083 - ℹ️ STARTING SCHEMA: scdl/plats-menus-collectifs\n",
      "2021-10-12 12:02:35.390230 -- ❌ No data downloaded for this schema.\n",
      "2021-10-12 12:02:35.390291 - ℹ️ STARTING SCHEMA: scdl/subventions\n",
      "2021-10-12 12:02:35.390436 -- ❌ No data downloaded for this schema.\n",
      "CPU times: user 5.69 s, sys: 37.7 ms, total: 5.73 s\n",
      "Wall time: 5.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for schema_name in config_dict.keys() :\n",
    "    \n",
    "    print('{} - ℹ️ STARTING SCHEMA: {}'.format(datetime.now(), schema_name))\n",
    "    \n",
    "    schema_data_path = Path(data_path) / schema_name.replace('/','_')\n",
    "    \n",
    "    if os.path.exists(schema_data_path) :\n",
    "        \n",
    "        schema_consolidated_data_path = Path(consolidated_data_path) / schema_name.replace('/','_')\n",
    "        schema_consolidated_data_path.mkdir(exist_ok=True)\n",
    "        \n",
    "        ref_table_path = os.path.join(ref_tables_path, 'ref_table_{}.csv'.format(schema_name.replace('/', '_')))\n",
    "        df_ref = pd.read_csv(ref_table_path) #(This file necessarily exists if data folder exists)\n",
    "        \n",
    "        #We will test if downloaded files are empty or not (so we set default values)\n",
    "        df_ref['is_empty'] = np.nan\n",
    "        df_ref.loc[(df_ref['is_downloaded'] == True), 'is_empty'] = False\n",
    "        \n",
    "        schema_dict = get_schema_dict(schema_name, schemas_catalogue_list)\n",
    "        \n",
    "        version_names_list = [col.replace('is_valid_v_','') for col in df_ref.columns if col.startswith('is_valid_v_')]\n",
    "        \n",
    "        for version in schema_dict['versions'] :\n",
    "            version_name = version['version_name']\n",
    "            if version_name in version_names_list :\n",
    "                df_ref_v = df_ref[(df_ref['is_valid_v_'+version_name] == True) & (df_ref['is_downloaded'] == True)]\n",
    "                \n",
    "                if len(df_ref_v) > 0 :\n",
    "                    #Get schema version parameters for ddup\n",
    "                    version_dict = requests.get(version['schema_url']).json()\n",
    "                    version_cols_list = [field_dict['name'] for field_dict in version_dict['fields']]\n",
    "                    \n",
    "                    if 'primaryKey' in version_dict.keys() :\n",
    "                        primary_key = version_dict['primaryKey']\n",
    "                    else :\n",
    "                        primary_key = None\n",
    "                        \n",
    "                    df_r_list = []\n",
    "                    \n",
    "                    for index,row in df_ref_v.iterrows():\n",
    "                        file_path = os.path.join(schema_data_path, row['dataset_slug'], '{}.csv'.format(row['resource_id']))\n",
    "                        with open(file_path,'rb') as f:\n",
    "                            encoding = chardet.detect(f.read()).get('encoding')\n",
    "                            if(encoding == 'Windows-1254'):\n",
    "                                encoding = 'iso-8859-1'\n",
    "                        \n",
    "                        df_r = pd.read_csv(file_path, sep=None, engine=\"python\", dtype='str', encoding=encoding, na_filter=False)\n",
    "                        \n",
    "                        if len(df_r) > 0 : #Keeping only non empty files\n",
    "                            #Keep only schema columns (and add empty columns for missing ones)\n",
    "                            df_r = df_r[[col for col in version_cols_list if col in df_r.columns]]\n",
    "                            for col in version_cols_list :\n",
    "                                if col not in df_r.columns :\n",
    "                                    df_r[col] = np.nan\n",
    "\n",
    "                            df_r['last_modified'] = row['resource_last_modified']\n",
    "                            df_r['datagouv_dataset_id'] = row['dataset_id']\n",
    "                            df_r['datagouv_resource_id'] = row['resource_id']\n",
    "                            df_r['datagouv_organization_or_owner'] = row['organization_or_owner']\n",
    "                            df_r_list += [df_r]\n",
    "                            \n",
    "                        else :\n",
    "                            df_ref.loc[(df_ref['resource_id'] == row['resource_id']), 'is_empty'] = True\n",
    "                    \n",
    "                    if len(df_r_list) >= 5 :\n",
    "                        df_conso = pd.concat(df_r_list, ignore_index=True)\n",
    "\n",
    "                        #Sorting by most recent (resource last modification date at the moment)\n",
    "                        df_conso = df_conso.sort_values('last_modified', ascending=False)\n",
    "\n",
    "                        #Deduplication\n",
    "                        if primary_key is not None :\n",
    "                            ddup_cols = primary_key\n",
    "                        else :\n",
    "                            ddup_cols = version_cols_list\n",
    "\n",
    "                        df_conso = df_conso.drop_duplicates(ddup_cols, keep='first').reset_index(drop=True)  \n",
    "                        \n",
    "                        #Avoid \"null\" value in CSV files\n",
    "                        df_conso = df_conso.fillna('')\n",
    "                        \n",
    "                        df_conso.to_csv(os.path.join(schema_consolidated_data_path, 'consolidation_{}_v_{}_{}.csv'.format(schema_name.replace('/','_'), version_name, consolidation_date_str)), index=False, encoding=\"utf-8\",na_rep='null')\n",
    "                        print('{} -- ✅ DONE: {} version {}'.format(datetime.today(), schema_name, version_name))\n",
    "                    \n",
    "                    else :\n",
    "                        print('{} -- ⚠️ Less than 5 (non-empty) valid resources for version {} : consolidation file is not built'.format(datetime.today(), version_name))\n",
    "                    \n",
    "                else :\n",
    "                    print('{} -- ⚠️ No valid resource for version {} of this schema'.format(datetime.today(), version_name))\n",
    "        \n",
    "        df_ref.to_csv(ref_table_path, index=False)\n",
    "    \n",
    "    else :\n",
    "        print('{} -- ❌ No data downloaded for this schema.'.format(datetime.today()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-12 12:18:16.667065 - ℹ️ STARTING SCHEMA: Archivistes75/registre_entrees\n",
      "2021-10-12 12:18:16.667481 -- ❌ No consolidated file for this schema.\n",
      "2021-10-12 12:18:16.679848 - ℹ️ STARTING SCHEMA: CEREMA/schema-arrete-circulation-marchandises\n",
      "2021-10-12 12:18:16.680125 -- ❌ No consolidated file for this schema.\n",
      "2021-10-12 12:18:16.692072 - ℹ️ STARTING SCHEMA: MTES-MCT/acceslibre-schema\n",
      "2021-10-12 12:18:16.692241 -- ❌ No consolidated file for this schema.\n",
      "2021-10-12 12:18:16.703748 - ℹ️ STARTING SCHEMA: NaturalSolutions/schema-arbre\n",
      "2021-10-12 12:18:16.703989 -- ❌ No consolidated file for this schema.\n",
      "2021-10-12 12:18:16.716180 - ℹ️ STARTING SCHEMA: arsante/schema-dae\n",
      "2021-10-12 12:18:16.716565 -- ❌ No consolidated file for this schema.\n",
      "2021-10-12 12:18:16.728458 - ℹ️ STARTING SCHEMA: datakode/schema-pei\n",
      "2021-10-12 12:18:16.728810 -- ❌ No consolidated file for this schema.\n",
      "2021-10-12 12:18:16.741020 - ℹ️ STARTING SCHEMA: etalab/schema-decp-dpa\n",
      "2021-10-12 12:18:16.741443 -- ❌ No consolidated file for this schema.\n",
      "2021-10-12 12:18:16.753447 - ℹ️ STARTING SCHEMA: etalab/schema-hautes-remunerations\n",
      "2021-10-12 12:18:16.753802 -- ❌ No consolidated file for this schema.\n",
      "2021-10-12 12:18:16.765845 - ℹ️ STARTING SCHEMA: etalab/schema-inclusion-numerique\n",
      "2021-10-12 12:18:16.766029 -- ❌ No consolidated file for this schema.\n",
      "2021-10-12 12:18:16.778226 - ℹ️ STARTING SCHEMA: etalab/schema-irve\n",
      "2021-10-12 12:18:18.489543 --- ✅ Version 2.0.2: Successfully updated consolidated file.\n",
      "2021-10-12 12:18:18.503604 - ℹ️ STARTING SCHEMA: etalab/schema-lieux-covoiturage\n",
      "2021-10-12 12:18:18.503733 -- ❌ No consolidated file for this schema.\n",
      "2021-10-12 12:18:18.515080 - ℹ️ STARTING SCHEMA: etalab/schema-passage-a-niveau\n",
      "2021-10-12 12:18:18.515351 -- ❌ No consolidated file for this schema.\n",
      "2021-10-12 12:18:18.525729 - ℹ️ STARTING SCHEMA: etalab/schema-sdirve\n",
      "2021-10-12 12:18:18.526030 -- ❌ No consolidated file for this schema.\n",
      "2021-10-12 12:18:18.535715 - ℹ️ STARTING SCHEMA: etalab/schema-stationnement\n",
      "2021-10-12 12:18:18.536043 -- ❌ No consolidated file for this schema.\n",
      "2021-10-12 12:18:18.545684 - ℹ️ STARTING SCHEMA: etalab/schema-stationnement-cyclable\n",
      "2021-10-12 12:18:18.545970 -- ❌ No consolidated file for this schema.\n",
      "2021-10-12 12:18:18.555560 - ℹ️ STARTING SCHEMA: etalab/schema-vehicules-faibles-emissions-renouvellement-parc\n",
      "2021-10-12 12:18:18.555812 -- ❌ No consolidated file for this schema.\n",
      "2021-10-12 12:18:18.566582 - ℹ️ STARTING SCHEMA: openmaraude/schema-stationstaxi\n",
      "2021-10-12 12:18:18.566756 -- ❌ No consolidated file for this schema.\n",
      "2021-10-12 12:18:18.576971 - ℹ️ STARTING SCHEMA: scdl/budget\n",
      "2021-10-12 12:18:18.577205 -- ❌ No consolidated file for this schema.\n",
      "2021-10-12 12:18:18.587315 - ℹ️ STARTING SCHEMA: scdl/catalogue\n",
      "2021-10-12 12:18:18.587590 -- ❌ No consolidated file for this schema.\n",
      "2021-10-12 12:18:18.597556 - ℹ️ STARTING SCHEMA: scdl/deliberations\n",
      "2021-10-12 12:18:18.597757 -- ❌ No consolidated file for this schema.\n",
      "2021-10-12 12:18:18.607658 - ℹ️ STARTING SCHEMA: scdl/equipements\n",
      "2021-10-12 12:18:18.607859 -- ❌ No consolidated file for this schema.\n",
      "2021-10-12 12:18:18.617703 - ℹ️ STARTING SCHEMA: scdl/menus-collectifs\n",
      "2021-10-12 12:18:18.617968 -- ❌ No consolidated file for this schema.\n",
      "2021-10-12 12:18:18.627688 - ℹ️ STARTING SCHEMA: scdl/plats-menus-collectifs\n",
      "2021-10-12 12:18:18.628209 -- ❌ No consolidated file for this schema.\n",
      "2021-10-12 12:18:18.637570 - ℹ️ STARTING SCHEMA: scdl/subventions\n",
      "2021-10-12 12:18:18.637841 -- ❌ No consolidated file for this schema.\n",
      "CPU times: user 323 ms, sys: 17.5 ms, total: 341 ms\n",
      "Wall time: 1.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for schema_name in config_dict.keys() :\n",
    "    \n",
    "    with open(config_path, 'r') as f :\n",
    "        config_dict = yaml.safe_load(f)\n",
    "    \n",
    "    print('{} - ℹ️ STARTING SCHEMA: {}'.format(datetime.now(), schema_name))\n",
    "    \n",
    "    schema_consolidated_data_path = Path(consolidated_data_path) / schema_name.replace('/','_')\n",
    "    \n",
    "    if os.path.exists(schema_consolidated_data_path) :\n",
    "        #Check if dataset_id is in config. If not, create a dataset on datagouv\n",
    "        schema_config = config_dict[schema_name]\n",
    "        if 'consolidated_dataset_id' not in schema_config.keys() :\n",
    "            response = create_schema_consolidation_dataset(schema_name, schemas_catalogue_list, api_url)\n",
    "            if response.status_code == 201 :\n",
    "                consolidated_dataset_id = response.json()['id']\n",
    "                update_config_file(schema_name, 'consolidated_dataset_id', consolidated_dataset_id, config_path)\n",
    "                print('{} -- 🟢 No consolidation dataset for this schema - Successfully created (id: {})'.format(datetime.today(), consolidated_dataset_id))\n",
    "            else :\n",
    "                print('{} -- 🔴 No consolidation dataset for this schema - Failed to create one'.format(datetime.today()))\n",
    "        else :\n",
    "            consolidated_dataset_id = schema_config['consolidated_dataset_id']\n",
    "            \n",
    "        schemas_report_dict[schema_name]['consolidated_dataset_id'] = consolidated_dataset_id\n",
    "            \n",
    "        #Creating last consolidation resources\n",
    "        version_names_list = [filename.replace('consolidation_'+schema_name.replace('/','_')+'_v_', '').replace('_'+ consolidation_date_str +'.csv','') for filename in os.listdir(schema_consolidated_data_path) if not filename.startswith('.')]\n",
    "        \n",
    "        for version_name in sorted(version_names_list) :\n",
    "            with open(config_path, 'r') as f :\n",
    "                config_dict = yaml.safe_load(f)\n",
    "        \n",
    "            schema = {\n",
    "                \"name\": schema_name,\n",
    "                \"version\": version_name\n",
    "            }\n",
    "            obj = {}\n",
    "            obj['schema'] = schema\n",
    "            obj['type'] = 'main'\n",
    "            obj['title'] = \"Dernière version consolidée (v{} du schéma) - {}\".format(version_name, consolidation_date_str)\n",
    "            \n",
    "            file_path = os.path.join(schema_consolidated_data_path, 'consolidation_{}_v_{}_{}.csv'.format(schema_name.replace('/','_'), version_name, consolidation_date_str))\n",
    "            \n",
    "            \n",
    "            #Uploading file (creating a new resource if version was not there before)\n",
    "            try :\n",
    "                r_id = config_dict[schema_name]['latest_resource_ids'][version_name]\n",
    "                url = api_url + 'datasets/' + consolidated_dataset_id + '/resources/' + r_id + '/upload/'\n",
    "                r_to_create = False\n",
    "                expected_status_code = 200\n",
    "                \n",
    "            except KeyError :\n",
    "                url = api_url + 'datasets/' + consolidated_dataset_id + '/upload/'\n",
    "                r_to_create = True\n",
    "                expected_status_code = 201\n",
    "            \n",
    "            with open(file_path, 'rb') as file:\n",
    "                files = {'file': (file_path.split('/')[-1], file.read())}\n",
    "            \n",
    "            response = requests.post(url, files=files, headers=HEADERS)\n",
    "\n",
    "            if response.status_code == expected_status_code :\n",
    "                if r_to_create == True :\n",
    "                    r_id = response.json()['id']\n",
    "                    update_config_version_resource_id(schema_name, version_name, r_id, config_path)\n",
    "                    print('{} --- ➕ New latest resource ID created for {} v{} (id: {})'.format(datetime.today(), schema_name, version_name, r_id))\n",
    "            else :\n",
    "                r_id = None\n",
    "                print('{} --- ⚠️ Version {}: file could not be uploaded.'.format(datetime.today(), version_name))\n",
    "                \n",
    "                \n",
    "            if r_id is not None :\n",
    "                r_url = api_url + 'datasets/{}/resources/{}/'.format(consolidated_dataset_id, r_id)\n",
    "                r_response = requests.put(r_url, json=obj, headers=HEADERS)\n",
    "\n",
    "                if r_response.status_code == 200 :\n",
    "                    if r_to_create == True :\n",
    "                        print('{} --- ✅ Version {}: Successfully created consolidated file.'.format(datetime.today(), version_name))\n",
    "                    else :\n",
    "                        print('{} --- ✅ Version {}: Successfully updated consolidated file.'.format(datetime.today(), version_name))\n",
    "                else :\n",
    "                    print('{} --- ⚠️ Version {}: file uploaded but metadata could not be updated.'.format(datetime.today(), version_name))\n",
    "                \n",
    "    else :\n",
    "        schemas_report_dict[schema_name]['consolidated_dataset_id'] = np.nan\n",
    "        print('{} -- ❌ No consolidated file for this schema.'.format(datetime.today()))\n",
    "\n",
    "#Reopening config file to update config_dict (in case it has to be reused right after)\n",
    "with open(config_path, 'r') as f :\n",
    "    config_dict = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schemas (versions) feedback loop on resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding needed infos for each resource in reference tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-12 12:20:11.787472 - ❌ No reference table for schema Archivistes75/registre_entrees\n",
      "2021-10-12 12:20:11.787779 - ❌ No reference table for schema CEREMA/schema-arrete-circulation-marchandises\n",
      "2021-10-12 12:20:11.788208 - ❌ No reference table for schema MTES-MCT/acceslibre-schema\n",
      "2021-10-12 12:20:11.788283 - ❌ No reference table for schema NaturalSolutions/schema-arbre\n",
      "2021-10-12 12:20:11.788460 - ❌ No reference table for schema arsante/schema-dae\n",
      "2021-10-12 12:20:11.788665 - ❌ No reference table for schema datakode/schema-pei\n",
      "2021-10-12 12:20:11.788869 - ❌ No reference table for schema etalab/schema-decp-dpa\n",
      "2021-10-12 12:20:11.789286 - ❌ No reference table for schema etalab/schema-hautes-remunerations\n",
      "2021-10-12 12:20:11.789493 - ❌ No reference table for schema etalab/schema-inclusion-numerique\n",
      "2021-10-12 12:20:11.827797 - ✅ Infos added for schema etalab/schema-irve\n",
      "2021-10-12 12:20:11.828091 - ❌ No reference table for schema etalab/schema-lieux-covoiturage\n",
      "2021-10-12 12:20:11.828276 - ❌ No reference table for schema etalab/schema-passage-a-niveau\n",
      "2021-10-12 12:20:11.828463 - ❌ No reference table for schema etalab/schema-sdirve\n",
      "2021-10-12 12:20:11.828684 - ❌ No reference table for schema etalab/schema-stationnement\n",
      "2021-10-12 12:20:11.828764 - ❌ No reference table for schema etalab/schema-stationnement-cyclable\n",
      "2021-10-12 12:20:11.828975 - ❌ No reference table for schema etalab/schema-vehicules-faibles-emissions-renouvellement-parc\n",
      "2021-10-12 12:20:11.829039 - ❌ No reference table for schema openmaraude/schema-stationstaxi\n",
      "2021-10-12 12:20:11.829080 - ❌ No reference table for schema scdl/budget\n",
      "2021-10-12 12:20:11.829113 - ❌ No reference table for schema scdl/catalogue\n",
      "2021-10-12 12:20:11.829147 - ❌ No reference table for schema scdl/deliberations\n",
      "2021-10-12 12:20:11.829331 - ❌ No reference table for schema scdl/equipements\n",
      "2021-10-12 12:20:11.829396 - ❌ No reference table for schema scdl/menus-collectifs\n",
      "2021-10-12 12:20:11.829448 - ❌ No reference table for schema scdl/plats-menus-collectifs\n",
      "2021-10-12 12:20:11.829590 - ❌ No reference table for schema scdl/subventions\n",
      "CPU times: user 39.3 ms, sys: 4.12 ms, total: 43.5 ms\n",
      "Wall time: 42.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for schema_name in config_dict.keys() :\n",
    "    \n",
    "    ref_table_path = os.path.join(ref_tables_path, 'ref_table_{}.csv'.format(schema_name.replace('/', '_')))\n",
    "    \n",
    "    if os.path.isfile(ref_table_path) :\n",
    "        df_ref = pd.read_csv(ref_table_path)\n",
    "\n",
    "        df_ref = add_most_recent_valid_version(df_ref)\n",
    "        df_ref['is_schema_version_to_update'] = df_ref.apply(is_schema_version_to_update, axis=1)\n",
    "        df_ref['is_schema_to_add'] = df_ref.apply(is_schema_to_add, axis=1)\n",
    "        df_ref['is_schema_to_drop'] = df_ref.apply(is_schema_to_drop, axis=1)\n",
    "        \n",
    "        df_ref.to_csv(ref_table_path, index=False)\n",
    "\n",
    "        print('{} - ✅ Infos added for schema {}'.format(datetime.today(), schema_name))\n",
    "        \n",
    "    else :\n",
    "        print('{} - ❌ No reference table for schema {}'.format(datetime.today(), schema_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating resources schemas and sending comments/mails to notify producers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️⚠️⚠️ **TODO: UNCOMMENT MAIL SENDING AND DISCUSSION COMMENTING (+ DELETE PRINTS) FOR NOTIFICATION TO PRODUCERS.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-12 12:44:23.439698 - ❌ No reference table for schema Archivistes75/registre_entrees\n",
      "2021-10-12 12:44:23.440106 - ❌ No reference table for schema CEREMA/schema-arrete-circulation-marchandises\n",
      "2021-10-12 12:44:23.440200 - ❌ No reference table for schema MTES-MCT/acceslibre-schema\n",
      "2021-10-12 12:44:23.440256 - ❌ No reference table for schema NaturalSolutions/schema-arbre\n",
      "2021-10-12 12:44:23.440320 - ❌ No reference table for schema arsante/schema-dae\n",
      "2021-10-12 12:44:23.440364 - ❌ No reference table for schema datakode/schema-pei\n",
      "2021-10-12 12:44:23.440405 - ❌ No reference table for schema etalab/schema-decp-dpa\n",
      "2021-10-12 12:44:23.440632 - ❌ No reference table for schema etalab/schema-hautes-remunerations\n",
      "2021-10-12 12:44:23.440861 - ❌ No reference table for schema etalab/schema-inclusion-numerique\n",
      "2021-10-12 12:44:46.576639 - ✅ Resources updated for schema etalab/schema-irve\n",
      "2021-10-12 12:44:46.576964 - ❌ No reference table for schema etalab/schema-lieux-covoiturage\n",
      "2021-10-12 12:44:46.577157 - ❌ No reference table for schema etalab/schema-passage-a-niveau\n",
      "2021-10-12 12:44:46.577333 - ❌ No reference table for schema etalab/schema-sdirve\n",
      "2021-10-12 12:44:46.577489 - ❌ No reference table for schema etalab/schema-stationnement\n",
      "2021-10-12 12:44:46.577542 - ❌ No reference table for schema etalab/schema-stationnement-cyclable\n",
      "2021-10-12 12:44:46.577577 - ❌ No reference table for schema etalab/schema-vehicules-faibles-emissions-renouvellement-parc\n",
      "2021-10-12 12:44:46.577611 - ❌ No reference table for schema openmaraude/schema-stationstaxi\n",
      "2021-10-12 12:44:46.577751 - ❌ No reference table for schema scdl/budget\n",
      "2021-10-12 12:44:46.577805 - ❌ No reference table for schema scdl/catalogue\n",
      "2021-10-12 12:44:46.577840 - ❌ No reference table for schema scdl/deliberations\n",
      "2021-10-12 12:44:46.577874 - ❌ No reference table for schema scdl/equipements\n",
      "2021-10-12 12:44:46.577904 - ❌ No reference table for schema scdl/menus-collectifs\n",
      "2021-10-12 12:44:46.577935 - ❌ No reference table for schema scdl/plats-menus-collectifs\n",
      "2021-10-12 12:44:46.578073 - ❌ No reference table for schema scdl/subventions\n",
      "CPU times: user 2.59 s, sys: 122 ms, total: 2.71 s\n",
      "Wall time: 23.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for schema_name in config_dict.keys() :\n",
    "    \n",
    "    ref_table_path = os.path.join(ref_tables_path, 'ref_table_{}.csv'.format(schema_name.replace('/', '_')))\n",
    "    \n",
    "    if os.path.isfile(ref_table_path) :\n",
    "        df_ref = pd.read_csv(ref_table_path)\n",
    "        df_ref['resource_schema_update_success'] = np.nan\n",
    "        df_ref['producer_notification_success'] = np.nan\n",
    "\n",
    "        for idx, row in df_ref.iterrows() :\n",
    "            if row['is_schema_version_to_update'] :\n",
    "                resource_update_success = update_resource_schema(api_url, row['dataset_id'], row['resource_id'], schema_name, row['most_recent_valid_version'])\n",
    "                df_ref.loc[(df_ref['resource_id'] == row['resource_id']), 'resource_schema_update_success'] = resource_update_success\n",
    "                \n",
    "                if resource_update_success == True :\n",
    "                    title = 'Mise à jour de la version de la métadonnée schéma'\n",
    "                    comment = updated_schema_comment_template.format(resource_title = row['resource_title'],\n",
    "                                                                     schema_name = schema_name,\n",
    "                                                                     initial_version_name = row['initial_version_name'],\n",
    "                                                                     most_recent_valid_version = row['most_recent_valid_version']\n",
    "                                                                    )\n",
    "                    #comment_post = post_comment_on_dataset(dataset_id=row['dataset_id'],\n",
    "                    #                                       title=title,\n",
    "                    #                                       comment=comment,\n",
    "                    #                                       api_url=api_url\n",
    "                    #                                      )\n",
    "                    #\n",
    "                    #producer_notification_success = (comment_post.status_code == 201)\n",
    "                    \n",
    "                    #df_ref.loc[(df_ref['resource_id'] == row['resource_id']), 'producer_notification_success'] = producer_notification_success\n",
    "                    #No notification at the moment:\n",
    "                    df_ref.loc[(df_ref['resource_id'] == row['resource_id']), 'producer_notification_success'] = False\n",
    "                    \n",
    "            \n",
    "            elif row['is_schema_to_add'] :\n",
    "                resource_update_success = add_resource_schema(api_url, row['dataset_id'], row['resource_id'], schema_name, row['most_recent_valid_version'])\n",
    "                df_ref.loc[(df_ref['resource_id'] == row['resource_id']), 'resource_schema_update_success'] = resource_update_success\n",
    "                \n",
    "                if resource_update_success == True :\n",
    "                    title = 'Ajout de la métadonnée schéma'\n",
    "                    comment = added_schema_comment_template.format(resource_title = row['resource_title'],\n",
    "                                                             schema_name = schema_name,\n",
    "                                                             most_recent_valid_version = row['most_recent_valid_version']\n",
    "                                                            )\n",
    "                    #comment_post = post_comment_on_dataset(dataset_id=row['dataset_id'],\n",
    "                    #                                       title=title,\n",
    "                    #                                       comment=comment,\n",
    "                    #                                       api_url=api_url\n",
    "                    #                                      )\n",
    "                    #\n",
    "                    #producer_notification_success = (comment_post.status_code == 201)\n",
    "                    #df_ref.loc[(df_ref['resource_id'] == row['resource_id']), 'producer_notification_success'] = producer_notification_success\n",
    "                    #No notification at the moment:\n",
    "                    df_ref.loc[(df_ref['resource_id'] == row['resource_id']), 'producer_notification_success'] = False\n",
    "            \n",
    "            #Right now, we don't drop schema and do no notification\n",
    "            elif row['is_schema_to_drop'] :\n",
    "            #    resource_update_success = delete_resource_schema(api_url, row['dataset_id'], row['resource_id'], schema_name)\n",
    "            #    df_ref.loc[(df_ref['resource_id'] == row['resource_id']), 'resource_schema_update_success'] = resource_update_success\n",
    "            #    \n",
    "            #    if resource_update_success == True :\n",
    "            #        title = 'Suppression de la métadonnée schéma'\n",
    "            #        \n",
    "            #        mails_type, mails_list = get_owner_or_admin_mails(row['dataset_id'], api_url)\n",
    "            #        \n",
    "            #        if len(mails_list) > 0 : #If we found some email addresses, we send mails\n",
    "            #            \n",
    "            #            if mails_type == 'organisation_admins' :\n",
    "            #                message = deleted_schema_mail_template_org.format(organisation_name=row['organization_or_owner'],\n",
    "            #                                                                  dataset_title=row['dataset_title'],\n",
    "            #                                                                  resource_title=row['resource_title'],\n",
    "            #                                                                  schema_name=schema_name,\n",
    "            #                                                                  schema_url=get_schema_dict(schema_name, schemas_catalogue_list)['schema_url'],\n",
    "            #                                                                  resource_url=row['resource_url']\n",
    "            #                                                                 )\n",
    "            #            elif mails_type == 'owner' :\n",
    "            #                message = deleted_schema_mail_template_own.format(dataset_title=row['dataset_title'],\n",
    "            #                                                                  resource_title=row['resource_title'],\n",
    "            #                                                                  schema_name=schema_name,\n",
    "            #                                                                  schema_url=get_schema_dict(schema_name, schemas_catalogue_list)['schema_url'],\n",
    "            #                                                                  resource_url=row['resource_url']\n",
    "            #                                                                 )\n",
    "            #                \n",
    "            #            \n",
    "            #            #Sending mail\n",
    "            #            \n",
    "            #            producer_notification_success_list = []\n",
    "            #            print('- {} | {}:'.format(row['dataset_title'], row['resource_title']))\n",
    "            #            for mail_to in mails_list :\n",
    "            #                #mail_send = send_email(subject=title,\n",
    "            #                #                       message=message,\n",
    "            #                #                       mail_from=mail_from,\n",
    "            #                #                       mail_to=mail_to,\n",
    "            #                #                       smtp_host=smtp_host,\n",
    "            #                #                       smtp_user=smtp_user,\n",
    "            #                #                       smtp_password=smtp_password)\n",
    "\n",
    "            #                #producer_notification_success_list += [(mail_send.status_code == 250)]\n",
    "            #            \n",
    "            #            #producer_notification_success = any(producer_notification_success_list) # Success if at least one person receives the mail\n",
    "            #            \n",
    "            #        else : #If no mail address, we post a comment on dataset\n",
    "            #            comment = deleted_schema_comment_template.format(resource_title=row['resource_title'],\n",
    "            #                                                             schema_name=schema_name,\n",
    "            #                                                             schema_url=get_schema_dict(schema_name, schemas_catalogue_list)['schema_url'],\n",
    "            #                                                             resource_url=row['resource_url']\n",
    "            #                                                            )\n",
    "            #            \n",
    "            #            #comment_post = post_comment_on_dataset(dataset_id=row['dataset_id'],\n",
    "            #            #                                       title=title,\n",
    "            #            #                                       comment=comment,\n",
    "            #            #                                       api_url=api_url\n",
    "            #            #                                      )\n",
    "            #        \n",
    "            #            #producer_notification_success = (comment_post.status_code == 201)\n",
    "            #        \n",
    "            #        #df_ref.loc[(df_ref['resource_id'] == row['resource_id']), 'producer_notification_success'] = producer_notification_success\n",
    "            \n",
    "                #TO DROP when schema will be deleted and producer notified:\n",
    "                df_ref.loc[(df_ref['resource_id'] == row['resource_id']), 'resource_schema_update_success'] = False\n",
    "                df_ref.loc[(df_ref['resource_id'] == row['resource_id']), 'producer_notification_success'] = False\n",
    "            \n",
    "        \n",
    "        df_ref.to_csv(ref_table_path, index=False)\n",
    "\n",
    "        print('{} - ✅ Resources updated for schema {}'.format(datetime.today(), schema_name))\n",
    "        \n",
    "    else :\n",
    "        print('{} - ❌ No reference table for schema {}'.format(datetime.today(), schema_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating consolidation documentation resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-12 12:49:50.867769 - ℹ️ STARTING SCHEMA: Archivistes75/registre_entrees\n",
      "2021-10-12 12:49:50.867955 -- ❌ No reference table for this schema.\n",
      "2021-10-12 12:49:50.879817 - ℹ️ STARTING SCHEMA: CEREMA/schema-arrete-circulation-marchandises\n",
      "2021-10-12 12:49:50.880168 -- ❌ No reference table for this schema.\n",
      "2021-10-12 12:49:50.891719 - ℹ️ STARTING SCHEMA: MTES-MCT/acceslibre-schema\n",
      "2021-10-12 12:49:50.892002 -- ❌ No reference table for this schema.\n",
      "2021-10-12 12:49:50.904852 - ℹ️ STARTING SCHEMA: NaturalSolutions/schema-arbre\n",
      "2021-10-12 12:49:50.905461 -- ❌ No reference table for this schema.\n",
      "2021-10-12 12:49:50.917992 - ℹ️ STARTING SCHEMA: arsante/schema-dae\n",
      "2021-10-12 12:49:50.918113 -- ❌ No reference table for this schema.\n",
      "2021-10-12 12:49:50.929845 - ℹ️ STARTING SCHEMA: datakode/schema-pei\n",
      "2021-10-12 12:49:50.930145 -- ❌ No reference table for this schema.\n",
      "2021-10-12 12:49:50.943482 - ℹ️ STARTING SCHEMA: etalab/schema-decp-dpa\n",
      "2021-10-12 12:49:50.943790 -- ❌ No reference table for this schema.\n",
      "2021-10-12 12:49:50.956542 - ℹ️ STARTING SCHEMA: etalab/schema-hautes-remunerations\n",
      "2021-10-12 12:49:50.956873 -- ❌ No reference table for this schema.\n",
      "2021-10-12 12:49:50.969859 - ℹ️ STARTING SCHEMA: etalab/schema-inclusion-numerique\n",
      "2021-10-12 12:49:50.970163 -- ❌ No reference table for this schema.\n",
      "2021-10-12 12:49:50.982649 - ℹ️ STARTING SCHEMA: etalab/schema-irve\n",
      "2021-10-12 12:49:51.692505 --- ✅ Successfully updated documentation file.\n",
      "2021-10-12 12:49:51.704454 - ℹ️ STARTING SCHEMA: etalab/schema-lieux-covoiturage\n",
      "2021-10-12 12:49:51.704718 -- ❌ No reference table for this schema.\n",
      "2021-10-12 12:49:51.716047 - ℹ️ STARTING SCHEMA: etalab/schema-passage-a-niveau\n",
      "2021-10-12 12:49:51.716287 -- ❌ No reference table for this schema.\n",
      "2021-10-12 12:49:51.726588 - ℹ️ STARTING SCHEMA: etalab/schema-sdirve\n",
      "2021-10-12 12:49:51.727080 -- ❌ No reference table for this schema.\n",
      "2021-10-12 12:49:51.736852 - ℹ️ STARTING SCHEMA: etalab/schema-stationnement\n",
      "2021-10-12 12:49:51.736983 -- ❌ No reference table for this schema.\n",
      "2021-10-12 12:49:51.746840 - ℹ️ STARTING SCHEMA: etalab/schema-stationnement-cyclable\n",
      "2021-10-12 12:49:51.747016 -- ❌ No reference table for this schema.\n",
      "2021-10-12 12:49:51.756828 - ℹ️ STARTING SCHEMA: etalab/schema-vehicules-faibles-emissions-renouvellement-parc\n",
      "2021-10-12 12:49:51.756958 -- ❌ No reference table for this schema.\n",
      "2021-10-12 12:49:51.766932 - ℹ️ STARTING SCHEMA: openmaraude/schema-stationstaxi\n",
      "2021-10-12 12:49:51.767250 -- ❌ No reference table for this schema.\n",
      "2021-10-12 12:49:51.777411 - ℹ️ STARTING SCHEMA: scdl/budget\n",
      "2021-10-12 12:49:51.777545 -- ❌ No reference table for this schema.\n",
      "2021-10-12 12:49:51.787337 - ℹ️ STARTING SCHEMA: scdl/catalogue\n",
      "2021-10-12 12:49:51.787589 -- ❌ No reference table for this schema.\n",
      "2021-10-12 12:49:51.797479 - ℹ️ STARTING SCHEMA: scdl/deliberations\n",
      "2021-10-12 12:49:51.797609 -- ❌ No reference table for this schema.\n",
      "2021-10-12 12:49:51.807617 - ℹ️ STARTING SCHEMA: scdl/equipements\n",
      "2021-10-12 12:49:51.807750 -- ❌ No reference table for this schema.\n",
      "2021-10-12 12:49:51.817613 - ℹ️ STARTING SCHEMA: scdl/menus-collectifs\n",
      "2021-10-12 12:49:51.817747 -- ❌ No reference table for this schema.\n",
      "2021-10-12 12:49:51.827564 - ℹ️ STARTING SCHEMA: scdl/plats-menus-collectifs\n",
      "2021-10-12 12:49:51.827695 -- ❌ No reference table for this schema.\n",
      "2021-10-12 12:49:51.842634 - ℹ️ STARTING SCHEMA: scdl/subventions\n",
      "2021-10-12 12:49:51.843001 -- ❌ No reference table for this schema.\n",
      "CPU times: user 317 ms, sys: 11 ms, total: 328 ms\n",
      "Wall time: 1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for schema_name in config_dict.keys() :\n",
    "    \n",
    "    ref_table_path = os.path.join(ref_tables_path, 'ref_table_{}.csv'.format(schema_name.replace('/', '_')))\n",
    "    \n",
    "    with open(config_path, 'r') as f :\n",
    "        config_dict = yaml.safe_load(f)\n",
    "    \n",
    "    print('{} - ℹ️ STARTING SCHEMA: {}'.format(datetime.now(), schema_name))\n",
    "    \n",
    "    schema_config = config_dict[schema_name]\n",
    "    \n",
    "    if os.path.isfile(ref_table_path) :\n",
    "    \n",
    "        if 'consolidated_dataset_id' in schema_config.keys() :\n",
    "            consolidated_dataset_id = schema_config['consolidated_dataset_id']\n",
    "            \n",
    "            obj = {}\n",
    "            obj['type'] = 'documentation'\n",
    "            obj['title'] = \"Documentation sur la consolidation - {}\".format(consolidation_date_str)\n",
    "\n",
    "            #Uploading documentation file (creating a new resource if version was not there before)\n",
    "            try :\n",
    "                doc_r_id = config_dict[schema_name]['documentation_resource_id']\n",
    "                url = api_url + 'datasets/' + consolidated_dataset_id + '/resources/' + doc_r_id + '/upload/'\n",
    "                doc_r_to_create = False\n",
    "                expected_status_code = 200\n",
    "\n",
    "            except KeyError :\n",
    "                url = api_url + 'datasets/' + consolidated_dataset_id + '/upload/'\n",
    "                doc_r_to_create = True\n",
    "                expected_status_code = 201\n",
    "\n",
    "            with open(ref_table_path, 'rb') as file:\n",
    "                files = {'file': (ref_table_path.split('/')[-1], file.read())}\n",
    "\n",
    "            response = requests.post(url, files=files, headers=HEADERS)\n",
    "            \n",
    "            if response.status_code == expected_status_code :\n",
    "                if doc_r_to_create == True :\n",
    "                    doc_r_id = response.json()['id']\n",
    "                    update_config_file(schema_name, 'documentation_resource_id', doc_r_id, config_path)\n",
    "                    print('{} --- ➕ New documentation resource ID created for {} (id: {})'.format(datetime.today(), schema_name, doc_r_id))\n",
    "            else :\n",
    "                doc_r_id = None\n",
    "                print('{} --- ⚠️ Documentation file could not be uploaded.'.format(datetime.today()))\n",
    "\n",
    "\n",
    "            if doc_r_id is not None :\n",
    "                doc_r_url = api_url + 'datasets/{}/resources/{}/'.format(consolidated_dataset_id, doc_r_id)\n",
    "                doc_r_response = requests.put(doc_r_url, json=obj, headers=HEADERS)\n",
    "                if doc_r_response.status_code == 200 :\n",
    "                    if doc_r_to_create == True :\n",
    "                        print('{} --- ✅ Successfully created documentation file.'.format(datetime.today()))\n",
    "                    else :\n",
    "                        print('{} --- ✅ Successfully updated documentation file.'.format(datetime.today()))\n",
    "                else :\n",
    "                    print('{} --- ⚠️ Documentation file uploaded but metadata could not be updated.'.format(datetime.today()))\n",
    "        \n",
    "        else :\n",
    "            print('{} -- ❌ No consolidation dataset ID for this schema.'.format(datetime.today()))\n",
    "            \n",
    "    else :\n",
    "        print('{} -- ❌ No reference table for this schema.'.format(datetime.today()))\n",
    "\n",
    "#Reopening config file to update config_dict (in case it has to be reused right after)\n",
    "with open(config_path, 'r') as f :\n",
    "    config_dict = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consolidation Reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report by schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports_list = []\n",
    "\n",
    "for schema_name in schemas_report_dict.keys() :\n",
    "    schema_report_dict = schemas_report_dict[schema_name]\n",
    "    schema_report_dict['schema_name'] = schema_name\n",
    "    reports_list += [schema_report_dict]\n",
    "    \n",
    "reports_df = pd.DataFrame(reports_list)\n",
    "\n",
    "reports_df = reports_df[['schema_name'] + [col for col in reports_df.columns if col != 'schema_name']].rename(columns={'config_created':'new_config_created'}) #rename to drop at next launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df_list = []\n",
    "for schema_name in config_dict.keys() :\n",
    "    \n",
    "    ref_table_path = os.path.join(ref_tables_path, 'ref_table_{}.csv'.format(schema_name.replace('/', '_')))\n",
    "    \n",
    "    if os.path.isfile(ref_table_path) :\n",
    "        df_ref = pd.read_csv(ref_table_path)\n",
    "        df_ref['schema_name'] = schema_name\n",
    "        df_ref['is_schema_version_updated'] = df_ref['is_schema_version_to_update'] & df_ref['resource_schema_update_success']\n",
    "        df_ref['is_schema_added'] = df_ref['is_schema_to_add'] & df_ref['resource_schema_update_success']\n",
    "        df_ref['is_schema_dropped'] = df_ref['is_schema_to_drop'] & df_ref['resource_schema_update_success']\n",
    "        df_ref['resource_schema_update_success'] = False\n",
    "        df_ref.to_csv(ref_table_path, index=False)\n",
    "        stats_df_list += [df_ref[['schema_name', 'is_schema_version_to_update', 'is_schema_to_add', 'is_schema_to_drop', 'resource_schema_update_success', 'is_schema_version_updated','is_schema_added', 'is_schema_dropped']].fillna(False).groupby('schema_name').sum().reset_index()]\n",
    "\n",
    "stats_df = pd.concat(stats_df_list).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>schema_name</th>\n",
       "      <th>is_schema_version_to_update</th>\n",
       "      <th>is_schema_to_add</th>\n",
       "      <th>is_schema_to_drop</th>\n",
       "      <th>resource_schema_update_success</th>\n",
       "      <th>is_schema_version_updated</th>\n",
       "      <th>is_schema_added</th>\n",
       "      <th>is_schema_dropped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>etalab/schema-irve</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>297</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          schema_name  is_schema_version_to_update  is_schema_to_add  \\\n",
       "0  etalab/schema-irve                          119                 0   \n",
       "\n",
       "   is_schema_to_drop  resource_schema_update_success  \\\n",
       "0                297                               0   \n",
       "\n",
       "   is_schema_version_updated  is_schema_added  is_schema_dropped  \n",
       "0                        119                0                  0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports_df = reports_df.merge(stats_df, on='schema_name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>schema_name</th>\n",
       "      <th>nb_versions</th>\n",
       "      <th>new_config_created</th>\n",
       "      <th>nb_versions_to_drop_in_config</th>\n",
       "      <th>nb_resources_found_by_schema</th>\n",
       "      <th>nb_resources_found_by_tags</th>\n",
       "      <th>nb_resources_found_by_search_words</th>\n",
       "      <th>nb_valid_resources</th>\n",
       "      <th>consolidated_dataset_id</th>\n",
       "      <th>is_schema_version_to_update</th>\n",
       "      <th>is_schema_to_add</th>\n",
       "      <th>is_schema_to_drop</th>\n",
       "      <th>resource_schema_update_success</th>\n",
       "      <th>is_schema_version_updated</th>\n",
       "      <th>is_schema_added</th>\n",
       "      <th>is_schema_dropped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>etalab/schema-irve</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>5448d3e0c751df01f85d0572</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>etalab/schema-decp-dpa</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scdl/catalogue</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scdl/deliberations</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scdl/equipements</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              schema_name  nb_versions  new_config_created  \\\n",
       "0      etalab/schema-irve            7                True   \n",
       "1  etalab/schema-decp-dpa            1                True   \n",
       "2          scdl/catalogue            2                True   \n",
       "3      scdl/deliberations            6                True   \n",
       "4        scdl/equipements            2                True   \n",
       "\n",
       "   nb_versions_to_drop_in_config  nb_resources_found_by_schema  \\\n",
       "0                            6.0                         430.0   \n",
       "1                            NaN                           NaN   \n",
       "2                            NaN                           NaN   \n",
       "3                            NaN                           NaN   \n",
       "4                            NaN                           NaN   \n",
       "\n",
       "   nb_resources_found_by_tags  nb_resources_found_by_search_words  \\\n",
       "0                         0.0                               248.0   \n",
       "1                         NaN                                 NaN   \n",
       "2                         NaN                                 NaN   \n",
       "3                         NaN                                 NaN   \n",
       "4                         NaN                                 NaN   \n",
       "\n",
       "   nb_valid_resources   consolidated_dataset_id  is_schema_version_to_update  \\\n",
       "0               127.0  5448d3e0c751df01f85d0572                        119.0   \n",
       "1                 NaN                       NaN                          NaN   \n",
       "2                 NaN                       NaN                          NaN   \n",
       "3                 NaN                       NaN                          NaN   \n",
       "4                 NaN                       NaN                          NaN   \n",
       "\n",
       "   is_schema_to_add  is_schema_to_drop  resource_schema_update_success  \\\n",
       "0               0.0              297.0                             0.0   \n",
       "1               NaN                NaN                             NaN   \n",
       "2               NaN                NaN                             NaN   \n",
       "3               NaN                NaN                             NaN   \n",
       "4               NaN                NaN                             NaN   \n",
       "\n",
       "   is_schema_version_updated  is_schema_added  is_schema_dropped  \n",
       "0                      119.0              0.0                0.0  \n",
       "1                        NaN              NaN                NaN  \n",
       "2                        NaN              NaN                NaN  \n",
       "3                        NaN              NaN                NaN  \n",
       "4                        NaN              NaN                NaN  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reports_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports_df.to_excel(os.path.join(report_tables_path, 'report_by_schema_{}.xlsx'.format(consolidation_date_str)), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed reports (by schema and resource source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-12 12:52:28.930177 - ❌ No reference table for schema Archivistes75/registre_entrees\n",
      "2021-10-12 12:52:28.930636 - ❌ No reference table for schema CEREMA/schema-arrete-circulation-marchandises\n",
      "2021-10-12 12:52:28.930711 - ❌ No reference table for schema MTES-MCT/acceslibre-schema\n",
      "2021-10-12 12:52:28.930881 - ❌ No reference table for schema NaturalSolutions/schema-arbre\n",
      "2021-10-12 12:52:28.930943 - ❌ No reference table for schema arsante/schema-dae\n",
      "2021-10-12 12:52:28.931142 - ❌ No reference table for schema datakode/schema-pei\n",
      "2021-10-12 12:52:28.931224 - ❌ No reference table for schema etalab/schema-decp-dpa\n",
      "2021-10-12 12:52:28.931407 - ❌ No reference table for schema etalab/schema-hautes-remunerations\n",
      "2021-10-12 12:52:28.931483 - ❌ No reference table for schema etalab/schema-inclusion-numerique\n",
      "2021-10-12 12:52:28.967465 - ✅ Report done for schema etalab/schema-irve\n",
      "2021-10-12 12:52:28.967582 - ❌ No reference table for schema etalab/schema-lieux-covoiturage\n",
      "2021-10-12 12:52:28.967626 - ❌ No reference table for schema etalab/schema-passage-a-niveau\n",
      "2021-10-12 12:52:28.967667 - ❌ No reference table for schema etalab/schema-sdirve\n",
      "2021-10-12 12:52:28.967702 - ❌ No reference table for schema etalab/schema-stationnement\n",
      "2021-10-12 12:52:28.967921 - ❌ No reference table for schema etalab/schema-stationnement-cyclable\n",
      "2021-10-12 12:52:28.967989 - ❌ No reference table for schema etalab/schema-vehicules-faibles-emissions-renouvellement-parc\n",
      "2021-10-12 12:52:28.968034 - ❌ No reference table for schema openmaraude/schema-stationstaxi\n",
      "2021-10-12 12:52:28.968074 - ❌ No reference table for schema scdl/budget\n",
      "2021-10-12 12:52:28.968224 - ❌ No reference table for schema scdl/catalogue\n",
      "2021-10-12 12:52:28.968281 - ❌ No reference table for schema scdl/deliberations\n",
      "2021-10-12 12:52:28.968319 - ❌ No reference table for schema scdl/equipements\n",
      "2021-10-12 12:52:28.968354 - ❌ No reference table for schema scdl/menus-collectifs\n",
      "2021-10-12 12:52:28.968387 - ❌ No reference table for schema scdl/plats-menus-collectifs\n",
      "2021-10-12 12:52:28.968419 - ❌ No reference table for schema scdl/subventions\n",
      "CPU times: user 32.4 ms, sys: 5.45 ms, total: 37.8 ms\n",
      "Wall time: 38.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for schema_name in config_dict.keys() :\n",
    "    \n",
    "    ref_table_path = os.path.join(ref_tables_path, 'ref_table_{}.csv'.format(schema_name.replace('/', '_')))\n",
    "    \n",
    "    if os.path.isfile(ref_table_path) :\n",
    "        df_ref = pd.read_csv(ref_table_path)        \n",
    "    \n",
    "        df_ref['total_nb_resources'] = 1\n",
    "        df_ref['error_type'].fillna('no-error', inplace=True)\n",
    "\n",
    "        cols_to_sum = ['total_nb_resources']\n",
    "        cols_to_sum += [col for col in df_ref.columns if col.startswith('is_')]\n",
    "        df_report = df_ref.groupby(['resource_found_by', 'error_type']).agg({col:sum for col in cols_to_sum}).reset_index()\n",
    "\n",
    "        df_report.to_excel(os.path.join(report_tables_path, 'report_table_{}.xlsx'.format(schema_name.replace('/', '_'))), index=False)\n",
    "\n",
    "        print('{} - ✅ Report done for schema {}'.format(datetime.today(), schema_name))\n",
    "        \n",
    "    else :\n",
    "        print('{} - ❌ No reference table for schema {}'.format(datetime.today(), schema_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
